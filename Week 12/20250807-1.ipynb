{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5eea46",
   "metadata": {},
   "source": [
    "```\n",
    "trl==0.19.1\n",
    "transformers \n",
    "datasets \n",
    "evaluate  \n",
    "huggingface_hub \n",
    "accelerate \n",
    "wandb \n",
    "scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a658bdc-d70b-47ec-912a-e7ddae4597e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"#########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74662167-ee59-45c5-bae9-6f7c3c5e08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b24ab572-6a9b-43b6-b3d0-bd8a9ea1a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.integrations import WandbCallback\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1987327-7426-419f-86ef-acd4c9ccecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    pipeline, \n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40dcebf-10f0-407e-8bae-19879ef07897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63db6be704b4768b2532e254cd2a29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9970e9-016d-4210-8ab0-5662789d759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset(\"jaehy12/news3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f364b59c-7b3c-4734-bc02-e467af9da8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35a0183-546f-46aa-99e4-48b0cd807618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_format(example):\n",
    "    return [\n",
    "            {\"role\": \"user\", \"content\": f\"다음 텍스트를 한국어로 간단히 요약 및 관련 키워를 추출해주세요:\\n{example['original']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"한국어 요약:\\n{example['summary']}\"}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f1546-2b50-4aea-995c-5f57d1b45121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '다음 텍스트를 한국어로 간단히 요약 및 관련 키워를 추출해주세요:\\n “동선 봐도 도움이 안 되는 것 같아요.\\n  어딘지 알아야 피해가고 조심할 텐데요.\\n ”“확진자가 다녀간 곳은 방역 마쳤는데 동선 공개는 그 부근 일대를 싹 다 죽이자는 것 같아요.\\n ” 최근 부천시 페이스북 신종 코로나바이러스 감염증(코로나19) 관련 게시물에는 확진자 동선 공개 범위를 성토하는 댓글이 여럿 달렸다.\\n  물류센터·교회 발 코로나19 확산이 지역사회 N차 감염으로 이어지면서 확진자 동선을 확대 공개해야 한다는 주장이 제기된 가운데 사생활 침해 등을 근거로 반대하는 의견도 나오면서 동선공개 논란에 다시 불이 붙는 모양새다.\\n  지난 2월 코로나19 초기엔 확진자 동선이 대부분 공개됐다.\\n  쇼핑몰을 방문한 확진자가 시간대별로 어느 매장을 찾았는지 등의 동선이 지자체 소셜네트워크서비스(SNS)에 게재됐다.\\n  이후 사생활 침해 논란이 일자 질본은 감염병 예방에 필요한 정보에 한해 확진자 정보를 공개하라는 권고사항을 발표했다.\\n  권고사항에는 증상 발생 2일 전부터 격리일까지의 시간, 감염을 우려할 만큼의 확진자와의 접촉이 일어난 장소 및 수단 등을 공개한다는 내용이 담겼다.\\n  해당 공간 내 모든 접촉자가 파악되면 공개하지 않을 수 있다는 단서도 추가됐다.\\n  확진자가 마지막 접촉자와 만날 일로부터 14일이 지나면 공개한 동선을 삭제할 것도 권고했다.\\n  확진 늘자 동선공개 확대 나선 지자체 물류센터·교회 등 집단감염에 이어 감염경로가 특정되지 않은 확진 사례가 늘면서 일부 지자체는 동선 공개 범위를 확대하고 있다.\\n  김포시는 지난 2일부터 확진자 이동 경로에 따른 동선 공개 원칙을 제한적으로 확대했다.\\n  시민 우려 불식을 위해 확진자 방문으로 접촉자가 다수 발생하고 확산이 우려되는 장소는 상호를 공개하기로 한 것이다.\\n  앞서 부천 118번 확진자인 A씨(31)가 한 제약회사 영업사원인 사실이 알려지면서 SNS에 그가 다닌 병원 정보가 공유됐다.\\n  장덕천 부천시장은 “SNS에 A씨가 평소 다니는 병원이 공유되고 있는데 평소 영업하는 곳이 모두 문제 되는 것이 아니라 증상발현 이틀 전 이후 방문한 곳이 문제가 된다.\\n  잘못된 정보를 경계해달라”고 말했다.\\n  이에 확진자 관련해 잘못된 정보가 퍼지는 것을 막기 위해서라도 보건당국이 확진자 정보를 자세히 공개해야 하다는 지적이 나왔다.\\n  부천시에 사는 김모(32)씨는 “깜깜이 확진자가 늘어서 걱정인데 온라인에 확진자 관련 루머가 많다”며 “관련 사항을 명확히 알려줬으면 좋겠다”고 말했다.\\n '},\n",
       " {'role': 'assistant',\n",
       "  'content': '한국어 요약:\\n물류센터·교회 발 코로나19 확산이 지역사회 N차 감염으로 이어지면서 확진자 동선을 확대 공개해야 한다는 주장이 제기된 가운데 사생활 침해 등을 근거로 반대하는 의견도 나오면서 동선공개 논란에 다시 불이 붙는 모양새다. 이후 사생활 침해 논란이 일자 질본은 감염병 예방에 필요한 정보에 한해 확진자 정보를 공개하라는 권고사항을 발표했다.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chat_format(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251fc74e-1ee7-471e-96c9-082227e32542",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = tokenizer.apply_chat_template(\n",
    "    get_chat_format(element), tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f301b30-996b-49b7-93d9-df3487cc9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"다음 텍스트를 한국어로 간단히 요약해주세요:\\n부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
    "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
    "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
    "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
    "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
    "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
    "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
    "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
    "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\"\"\"\n",
    "\n",
    "def change_inference_chat_format(input_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "\t{\"role\": \"assistant\", \"content\": \"\"\"부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
    "     유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"중요한 키워드 5개를 뽑아주세요.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623c8dff-3933-4a6a-a15a-b6bcdee1693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = change_inference_chat_format(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dae49f9-d399-4f83-b2ce-7e1038178f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"다음 텍스트를 한국어로 간단히 요약해주세요:\\n부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\\n유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\\n11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\\nA씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\\n경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\\n반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\\n사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\\n사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\\n경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\\n     유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\"},\n",
       " {'role': 'user', 'content': '중요한 키워드 5개를 뽑아주세요.'},\n",
       " {'role': 'assistant', 'content': ''}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd0fa9e-cbc6-494e-b45c-4f5aa56931d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "다음 텍스트를 한국어로 간단히 요약해주세요:\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
      "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
      "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
      "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
      "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
      "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\n",
      "model\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "     유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "user\n",
      "중요한 키워드 5개를 뽑아주세요.\n",
      "model\n",
      "\n",
      "model\n",
      "- 부산의 한 왕복 2차선 도로에서 역주행 사고\n",
      "- 배달 오토바이 운전자\n",
      "- 고등학생\n",
      "- 유족\n",
      "- 늑장 대응\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    prompt, \n",
    "    tokenize=True, \n",
    "    add_generation_prompt=True, \n",
    "    return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.to(model.device), \n",
    "    max_new_tokens=256\n",
    "    )\n",
    "print(tokenizer.decode(\n",
    "    outputs[0], \n",
    "    skip_special_tokens=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd793ee-6264-4069-9433-8285131bdc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_inference_chat_format(input_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"한국어 요약:\\n\"}\n",
    "    ]\n",
    "prompt = change_inference_chat_format(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e551bc-7e94-43dc-8803-fadd47c407c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"다음 텍스트를 한국어로 간단히 요약해주세요:\\n부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\\n유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\\n11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\\nA씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\\n경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\\n반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\\n사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\\n사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\\n경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\"},\n",
       " {'role': 'assistant', 'content': '한국어 요약:\\n'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "706a97f6-a3e2-43d0-ad04-69a724ddb858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "다음 텍스트를 한국어로 간단히 요약해주세요:\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
      "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
      "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
      "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
      "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
      "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\n",
      "model\n",
      "한국어 요약:\n",
      "model\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다. 유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다. 경찰은 교통사고처리법상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.apply_chat_template(prompt,\n",
    "                                       tokenize=True, \n",
    "                                       add_generation_prompt=True,\n",
    "                                       return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(inputs, max_new_tokens=256, use_cache=True)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0562035-379a-41de-8824-eb436c17b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_inference_chat_format(input_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"다음 텍스트를 한국어로 간단히 요약하고, 관련된 5개의 키워를 추출해주세요:\\n{input_text}\"},\n",
    "\t{\"role\": \"assistant\", \"content\": \"\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ce24855-0b2e-4343-a93c-9e759795e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = change_inference_chat_format(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c034d4da-0ab6-4154-947c-21d8b24a158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(prompt, \n",
    "                                       tokenize=True, \n",
    "                                       add_generation_prompt=True, \n",
    "                                       return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(inputs, max_new_tokens=256, use_cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "732b67b2-8b80-4e6f-85b2-63cbf7da96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "다음 텍스트를 한국어로 간단히 요약하고, 관련된 5개의 키워를 추출해주세요:\n",
      "다음 텍스트를 한국어로 간단히 요약해주세요:\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
      "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
      "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
      "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
      "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
      "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\n",
      "model\n",
      "\n",
      "model\n",
      "* 부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "\n",
      "\n",
      "* 유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "\n",
      "\n",
      "* A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "\n",
      "\n",
      "* 경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려 반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다.\n",
      "\n",
      "\n",
      "* 사고를 낸 A씨는 술을 마시거나 약\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0cbcbf-1794-413c-988a-660ba7b3f910",
   "metadata": {},
   "source": [
    "# 키워드 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cedbc58-10f2-4053-8f25-06248e2065ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736b8e17-3f50-4253-98f7-127a473dfb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_word_prompt(input_text, summary_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "    {\"role\": \"assistant\", \"content\": f\"{summary_text}\"},\n",
    "    {\"role\": \"user\", \"content\": \"중요한 키워드 5개를 뽑아주세요.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "\n",
    "def extract_keywords_batch(batch):\n",
    "    prompts = [key_word_prompt(original, summary) for original, summary in zip(batch[\"original\"], batch[\"summary\"])]\n",
    "\n",
    "    generated_texts = pipe(prompts, max_new_tokens=150, return_full_text=False)\n",
    "    keywords = [gen_text[0][\"generated_text\"] for gen_text in generated_texts]\n",
    "    batch[\"keywords\"] = keywords\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb6bca02-39ff-44a5-8f24-db0052977b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['original', 'summary'],\n",
       "    num_rows: 24300\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e950fcb-9415-48e5-8724-7bce985bd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b52c0527-b1e7-45e2-b777-3305f3e92972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['original', 'summary'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e02c3acc-ceab-4400-8ae7-f6137f9836ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479f2a98cc6b4dbfa61ec2c6088a2880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = sample_dataset.map(extract_keywords_batch, batched=True, batch_size=20)  # 적절한 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a28cc211-d5ca-475c-b363-d4ba47242e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': '전두환 정권을 흔들었던 \\'큰 손\\' 장영자의 네 번째 유죄가 확정됐다.\\n  혐의는 사기, 징역은 4년이다.\\n  대법원 2부(주심 박상옥 대법관)는 9일 무죄를 주장한 장씨의 상고를 기각했다.\\n  장씨는 지인들에게서 세 차례에 걸쳐 6억여원을 가로채고 이들에게 위조 수표로 수억원을 요구한 혐의를 받는다.\\n  올해로 76세를 맞은 장씨는 이미 복역을 마친 29년을 포함해 인생의 절반가량인 33년을 감옥에서 보내게됐다.\\n   우수한 인재에게만 허락된다는 숙명여대 \\'5월의 여왕(메이퀸)\\' 출신인 장영자의 노년이 씁쓸하다.\\n  장씨는 전두환 전 대통령의 처삼촌인 고(故) 이규광씨의 처제이자, 중앙정보부 차장이었던 고(故) 이철희씨의 아내였다.\\n  전두환 정권 흔든 장영자의 삶장씨의 앞선 범행과 비교해 네 번째 사기 액수는 그 규모가 상당히 줄어든 편이다.\\n  장씨는 1980년대 전두환 전 대통령과 남편을 내세워 자금 압박에 시달리던 기업에 자금을 빌려준 뒤 몇 배에 달하는 어음을 할인 유통하며 이득을 챙겼다.\\n  그 규모가 총 7111억원에 달했다.\\n  장씨는 이중 6404억원의 어음을 할인해 사용했다.\\n   실체가 없던 어음은 부도가 났고 기업들은 도산했다.\\n  장씨는 이 첫 번째 사기로 15년형을 선고받았다.\\n  10년만인 1992년에 가석방됐다.\\n  전두환 전 대통령의 부인 이순자씨는 자서전 『당신은 외롭지 않다』에서 이를 \"조금씩 민심도 안정되고 경제도 생기를 되찾아 (남편이) 자신감을 얻던 시점에 날벼락같이 찾아온 횡액과도 같은 사건\"이라 회고했다.\\n  장씨가 당시 법정에서 아직 시중에 유통중인 어음이 있다며 \"경제는 유통\"\"나는 권력투쟁의 희생양이라\"이라 했던 말은 유행어가 됐다.\\n  \\'장영자 어음할인 사건\\' 수사 축소 의혹으로 두 명의 법무부 장관이 경질됐다.\\n   \"누나 성질 급하다\" 70대 장영자의 돈 요구장씨는 출소한지 2년만인 1994년에 140억원대 차용 사기를 저질렀다.\\n  두 번째 사기로 징역 4년을 받았다.\\n  장씨는 1998년 광복절 특사로 풀려났다.\\n  하지만 2년만인 2000년 220억원대 구권화폐 사기로 또다시 구속돼 15년형을 받았다.\\n  그게 세 번째 사기다.\\n  이날 확정이 된 장씨의 네 번째 사기는 2015년 1월 출소하고 7개월 만에 저지른 범행이다.\\n  장씨에게 유죄를 선고한 1·2심 재판장은 \"장씨가 동종범죄로 처벌받은 전력이 있고 누범기간 중에 범죄를 저질렀다\"고 지적했다.\\n ',\n",
       " 'summary': \"전두환 정권을 흔들었던 '큰 손' 장영자의 네 번째 유죄가 확정됐다. 장씨는 지인들에게서 세 차례에 걸쳐 6억여원을 가로채고 이들에게 위조 수표로 수억원을 요구한 혐의를 받는다. 올해로 76세를 맞은 장씨는 이미 복역을 마친 29년을 포함해 인생의 절반가량인 33년을 감옥에서 보내게됐다.\",\n",
       " 'keywords': \"1. '큰 손' 장영자\\n2. 전두환 정권\\n3. 네 번째 유죄\\n4. 지인\\n5. 위조 수표\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17097af1-934e-40a9-bc2c-5d22b1c9c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_keyword_summary_format(example):\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": f\"다음 텍스트를 한국어로 간단히 요약 및 관련 키워를 추출해주세요:\\n{example['original']}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"한국어 요약:{example['summary']}\\n키워드:{example['keywords']}\"}\n",
    "    ]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    chat_keyword_summary_format(sample_dataset[0]), tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bb90bd5-65a2-4f94-a625-a871763cc0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\n다음 텍스트를 한국어로 간단히 요약 및 관련 키워를 추출해주세요:\\n전두환 정권을 흔들었던 \\'큰 손\\' 장영자의 네 번째 유죄가 확정됐다.\\n  혐의는 사기, 징역은 4년이다.\\n  대법원 2부(주심 박상옥 대법관)는 9일 무죄를 주장한 장씨의 상고를 기각했다.\\n  장씨는 지인들에게서 세 차례에 걸쳐 6억여원을 가로채고 이들에게 위조 수표로 수억원을 요구한 혐의를 받는다.\\n  올해로 76세를 맞은 장씨는 이미 복역을 마친 29년을 포함해 인생의 절반가량인 33년을 감옥에서 보내게됐다.\\n   우수한 인재에게만 허락된다는 숙명여대 \\'5월의 여왕(메이퀸)\\' 출신인 장영자의 노년이 씁쓸하다.\\n  장씨는 전두환 전 대통령의 처삼촌인 고(故) 이규광씨의 처제이자, 중앙정보부 차장이었던 고(故) 이철희씨의 아내였다.\\n  전두환 정권 흔든 장영자의 삶장씨의 앞선 범행과 비교해 네 번째 사기 액수는 그 규모가 상당히 줄어든 편이다.\\n  장씨는 1980년대 전두환 전 대통령과 남편을 내세워 자금 압박에 시달리던 기업에 자금을 빌려준 뒤 몇 배에 달하는 어음을 할인 유통하며 이득을 챙겼다.\\n  그 규모가 총 7111억원에 달했다.\\n  장씨는 이중 6404억원의 어음을 할인해 사용했다.\\n   실체가 없던 어음은 부도가 났고 기업들은 도산했다.\\n  장씨는 이 첫 번째 사기로 15년형을 선고받았다.\\n  10년만인 1992년에 가석방됐다.\\n  전두환 전 대통령의 부인 이순자씨는 자서전 『당신은 외롭지 않다』에서 이를 \"조금씩 민심도 안정되고 경제도 생기를 되찾아 (남편이) 자신감을 얻던 시점에 날벼락같이 찾아온 횡액과도 같은 사건\"이라 회고했다.\\n  장씨가 당시 법정에서 아직 시중에 유통중인 어음이 있다며 \"경제는 유통\"\"나는 권력투쟁의 희생양이라\"이라 했던 말은 유행어가 됐다.\\n  \\'장영자 어음할인 사건\\' 수사 축소 의혹으로 두 명의 법무부 장관이 경질됐다.\\n   \"누나 성질 급하다\" 70대 장영자의 돈 요구장씨는 출소한지 2년만인 1994년에 140억원대 차용 사기를 저질렀다.\\n  두 번째 사기로 징역 4년을 받았다.\\n  장씨는 1998년 광복절 특사로 풀려났다.\\n  하지만 2년만인 2000년 220억원대 구권화폐 사기로 또다시 구속돼 15년형을 받았다.\\n  그게 세 번째 사기다.\\n  이날 확정이 된 장씨의 네 번째 사기는 2015년 1월 출소하고 7개월 만에 저지른 범행이다.\\n  장씨에게 유죄를 선고한 1·2심 재판장은 \"장씨가 동종범죄로 처벌받은 전력이 있고 누범기간 중에 범죄를 저질렀다\"고 지적했다.<end_of_turn>\\n<start_of_turn>model\\n한국어 요약:전두환 정권을 흔들었던 \\'큰 손\\' 장영자의 네 번째 유죄가 확정됐다. 장씨는 지인들에게서 세 차례에 걸쳐 6억여원을 가로채고 이들에게 위조 수표로 수억원을 요구한 혐의를 받는다. 올해로 76세를 맞은 장씨는 이미 복역을 마친 29년을 포함해 인생의 절반가량인 33년을 감옥에서 보내게됐다.\\n키워드:1. \\'큰 손\\' 장영자\\n2. 전두환 정권\\n3. 네 번째 유죄\\n4. 지인\\n5. 위조 수표<end_of_turn>\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f73289e-9994-4bfa-a1d0-07ebed4ce15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f64348710a4475fbad7195d3a862c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def tokenize(element):\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        chat_keyword_summary_format(element), tokenize=False\n",
    "    ) + EOS_TOKEN\n",
    "    outputs = tokenizer(formatted)\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tokenized_sample_dataset = sample_dataset.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca860099-2d47-495d-8591-df9848e43043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': '전두환 정권을 흔들었던 \\'큰 손\\' 장영자의 네 번째 유죄가 확정됐다.\\n  혐의는 사기, 징역은 4년이다.\\n  대법원 2부(주심 박상옥 대법관)는 9일 무죄를 주장한 장씨의 상고를 기각했다.\\n  장씨는 지인들에게서 세 차례에 걸쳐 6억여원을 가로채고 이들에게 위조 수표로 수억원을 요구한 혐의를 받는다.\\n  올해로 76세를 맞은 장씨는 이미 복역을 마친 29년을 포함해 인생의 절반가량인 33년을 감옥에서 보내게됐다.\\n   우수한 인재에게만 허락된다는 숙명여대 \\'5월의 여왕(메이퀸)\\' 출신인 장영자의 노년이 씁쓸하다.\\n  장씨는 전두환 전 대통령의 처삼촌인 고(故) 이규광씨의 처제이자, 중앙정보부 차장이었던 고(故) 이철희씨의 아내였다.\\n  전두환 정권 흔든 장영자의 삶장씨의 앞선 범행과 비교해 네 번째 사기 액수는 그 규모가 상당히 줄어든 편이다.\\n  장씨는 1980년대 전두환 전 대통령과 남편을 내세워 자금 압박에 시달리던 기업에 자금을 빌려준 뒤 몇 배에 달하는 어음을 할인 유통하며 이득을 챙겼다.\\n  그 규모가 총 7111억원에 달했다.\\n  장씨는 이중 6404억원의 어음을 할인해 사용했다.\\n   실체가 없던 어음은 부도가 났고 기업들은 도산했다.\\n  장씨는 이 첫 번째 사기로 15년형을 선고받았다.\\n  10년만인 1992년에 가석방됐다.\\n  전두환 전 대통령의 부인 이순자씨는 자서전 『당신은 외롭지 않다』에서 이를 \"조금씩 민심도 안정되고 경제도 생기를 되찾아 (남편이) 자신감을 얻던 시점에 날벼락같이 찾아온 횡액과도 같은 사건\"이라 회고했다.\\n  장씨가 당시 법정에서 아직 시중에 유통중인 어음이 있다며 \"경제는 유통\"\"나는 권력투쟁의 희생양이라\"이라 했던 말은 유행어가 됐다.\\n  \\'장영자 어음할인 사건\\' 수사 축소 의혹으로 두 명의 법무부 장관이 경질됐다.\\n   \"누나 성질 급하다\" 70대 장영자의 돈 요구장씨는 출소한지 2년만인 1994년에 140억원대 차용 사기를 저질렀다.\\n  두 번째 사기로 징역 4년을 받았다.\\n  장씨는 1998년 광복절 특사로 풀려났다.\\n  하지만 2년만인 2000년 220억원대 구권화폐 사기로 또다시 구속돼 15년형을 받았다.\\n  그게 세 번째 사기다.\\n  이날 확정이 된 장씨의 네 번째 사기는 2015년 1월 출소하고 7개월 만에 저지른 범행이다.\\n  장씨에게 유죄를 선고한 1·2심 재판장은 \"장씨가 동종범죄로 처벌받은 전력이 있고 누범기간 중에 범죄를 저질렀다\"고 지적했다.\\n ',\n",
       " 'summary': \"전두환 정권을 흔들었던 '큰 손' 장영자의 네 번째 유죄가 확정됐다. 장씨는 지인들에게서 세 차례에 걸쳐 6억여원을 가로채고 이들에게 위조 수표로 수억원을 요구한 혐의를 받는다. 올해로 76세를 맞은 장씨는 이미 복역을 마친 29년을 포함해 인생의 절반가량인 33년을 감옥에서 보내게됐다.\",\n",
       " 'keywords': \"1. '큰 손' 장영자\\n2. 전두환 정권\\n3. 네 번째 유죄\\n4. 지인\\n5. 위조 수표\",\n",
       " 'input_ids': [2,\n",
       "  2,\n",
       "  106,\n",
       "  1645,\n",
       "  108,\n",
       "  236039,\n",
       "  238036,\n",
       "  235248,\n",
       "  242756,\n",
       "  50691,\n",
       "  236791,\n",
       "  114490,\n",
       "  236770,\n",
       "  236375,\n",
       "  127149,\n",
       "  238335,\n",
       "  239055,\n",
       "  73713,\n",
       "  239618,\n",
       "  60709,\n",
       "  187003,\n",
       "  141107,\n",
       "  239779,\n",
       "  236791,\n",
       "  75943,\n",
       "  238483,\n",
       "  237138,\n",
       "  237014,\n",
       "  96673,\n",
       "  235292,\n",
       "  108,\n",
       "  237045,\n",
       "  238928,\n",
       "  239457,\n",
       "  35467,\n",
       "  239765,\n",
       "  236392,\n",
       "  235248,\n",
       "  244088,\n",
       "  237290,\n",
       "  238220,\n",
       "  240080,\n",
       "  777,\n",
       "  241341,\n",
       "  119312,\n",
       "  235303,\n",
       "  60318,\n",
       "  237759,\n",
       "  236645,\n",
       "  236137,\n",
       "  123722,\n",
       "  170174,\n",
       "  46355,\n",
       "  242903,\n",
       "  236361,\n",
       "  69781,\n",
       "  236864,\n",
       "  244908,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  246907,\n",
       "  236137,\n",
       "  236214,\n",
       "  17309,\n",
       "  236386,\n",
       "  235269,\n",
       "  235248,\n",
       "  241330,\n",
       "  238071,\n",
       "  236648,\n",
       "  235248,\n",
       "  235310,\n",
       "  237029,\n",
       "  61742,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  236800,\n",
       "  239085,\n",
       "  237399,\n",
       "  235248,\n",
       "  235284,\n",
       "  237092,\n",
       "  235278,\n",
       "  237014,\n",
       "  239308,\n",
       "  100872,\n",
       "  237047,\n",
       "  242067,\n",
       "  26801,\n",
       "  239085,\n",
       "  237956,\n",
       "  235275,\n",
       "  236214,\n",
       "  235248,\n",
       "  235315,\n",
       "  236666,\n",
       "  60331,\n",
       "  242903,\n",
       "  236791,\n",
       "  40712,\n",
       "  237199,\n",
       "  236511,\n",
       "  60318,\n",
       "  241215,\n",
       "  236137,\n",
       "  36203,\n",
       "  236464,\n",
       "  236791,\n",
       "  28693,\n",
       "  238316,\n",
       "  88513,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  34805,\n",
       "  236589,\n",
       "  215895,\n",
       "  236554,\n",
       "  48740,\n",
       "  91292,\n",
       "  241569,\n",
       "  236179,\n",
       "  180850,\n",
       "  242391,\n",
       "  235248,\n",
       "  235318,\n",
       "  242086,\n",
       "  237386,\n",
       "  237399,\n",
       "  236392,\n",
       "  23248,\n",
       "  236375,\n",
       "  240478,\n",
       "  236464,\n",
       "  11464,\n",
       "  215895,\n",
       "  41423,\n",
       "  237602,\n",
       "  22618,\n",
       "  238946,\n",
       "  236375,\n",
       "  22618,\n",
       "  242086,\n",
       "  237399,\n",
       "  236392,\n",
       "  73713,\n",
       "  237302,\n",
       "  236511,\n",
       "  235248,\n",
       "  246907,\n",
       "  236137,\n",
       "  236791,\n",
       "  101260,\n",
       "  236214,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  240256,\n",
       "  237138,\n",
       "  236375,\n",
       "  235248,\n",
       "  235324,\n",
       "  235318,\n",
       "  237533,\n",
       "  236791,\n",
       "  207221,\n",
       "  236648,\n",
       "  60318,\n",
       "  241215,\n",
       "  236214,\n",
       "  22573,\n",
       "  122447,\n",
       "  238071,\n",
       "  236392,\n",
       "  41645,\n",
       "  240471,\n",
       "  235248,\n",
       "  235284,\n",
       "  235315,\n",
       "  237029,\n",
       "  236392,\n",
       "  157329,\n",
       "  237138,\n",
       "  30743,\n",
       "  237889,\n",
       "  236137,\n",
       "  191532,\n",
       "  238559,\n",
       "  236361,\n",
       "  240833,\n",
       "  236589,\n",
       "  235248,\n",
       "  235304,\n",
       "  235304,\n",
       "  237029,\n",
       "  236392,\n",
       "  99091,\n",
       "  242067,\n",
       "  22803,\n",
       "  29283,\n",
       "  238151,\n",
       "  237458,\n",
       "  244908,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  140,\n",
       "  237312,\n",
       "  236669,\n",
       "  236511,\n",
       "  30743,\n",
       "  238360,\n",
       "  70471,\n",
       "  237598,\n",
       "  189305,\n",
       "  241155,\n",
       "  238602,\n",
       "  161509,\n",
       "  235248,\n",
       "  241594,\n",
       "  238068,\n",
       "  237386,\n",
       "  236800,\n",
       "  777,\n",
       "  235308,\n",
       "  237699,\n",
       "  236137,\n",
       "  41896,\n",
       "  240292,\n",
       "  235278,\n",
       "  238519,\n",
       "  235832,\n",
       "  246662,\n",
       "  36346,\n",
       "  82366,\n",
       "  237502,\n",
       "  236589,\n",
       "  60318,\n",
       "  237759,\n",
       "  236645,\n",
       "  236137,\n",
       "  61138,\n",
       "  237029,\n",
       "  235832,\n",
       "  235248,\n",
       "  251556,\n",
       "  245471,\n",
       "  188898,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  31087,\n",
       "  238928,\n",
       "  239457,\n",
       "  31087,\n",
       "  26801,\n",
       "  238693,\n",
       "  240446,\n",
       "  236137,\n",
       "  106204,\n",
       "  240567,\n",
       "  242913,\n",
       "  236589,\n",
       "  46749,\n",
       "  235278,\n",
       "  236582,\n",
       "  235275,\n",
       "  11464,\n",
       "  240753,\n",
       "  239830,\n",
       "  241215,\n",
       "  236137,\n",
       "  106204,\n",
       "  236939,\n",
       "  235832,\n",
       "  236645,\n",
       "  235269,\n",
       "  47250,\n",
       "  241717,\n",
       "  173499,\n",
       "  237092,\n",
       "  91292,\n",
       "  237199,\n",
       "  235832,\n",
       "  238220,\n",
       "  240080,\n",
       "  46749,\n",
       "  235278,\n",
       "  236582,\n",
       "  235275,\n",
       "  11464,\n",
       "  240644,\n",
       "  240498,\n",
       "  241215,\n",
       "  236137,\n",
       "  23745,\n",
       "  238151,\n",
       "  129761,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237045,\n",
       "  238928,\n",
       "  239457,\n",
       "  35467,\n",
       "  239765,\n",
       "  235248,\n",
       "  244088,\n",
       "  239227,\n",
       "  60318,\n",
       "  237759,\n",
       "  236645,\n",
       "  236137,\n",
       "  235248,\n",
       "  242928,\n",
       "  237199,\n",
       "  241215,\n",
       "  236137,\n",
       "  192757,\n",
       "  237700,\n",
       "  235248,\n",
       "  240696,\n",
       "  238356,\n",
       "  237233,\n",
       "  51732,\n",
       "  237905,\n",
       "  237138,\n",
       "  123722,\n",
       "  170174,\n",
       "  17309,\n",
       "  236386,\n",
       "  235248,\n",
       "  241377,\n",
       "  236669,\n",
       "  236214,\n",
       "  20350,\n",
       "  235248,\n",
       "  240753,\n",
       "  237551,\n",
       "  236361,\n",
       "  36203,\n",
       "  238272,\n",
       "  239055,\n",
       "  184434,\n",
       "  236770,\n",
       "  239227,\n",
       "  136188,\n",
       "  61742,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  235248,\n",
       "  235274,\n",
       "  235315,\n",
       "  235321,\n",
       "  235276,\n",
       "  237029,\n",
       "  236800,\n",
       "  31087,\n",
       "  238928,\n",
       "  239457,\n",
       "  31087,\n",
       "  26801,\n",
       "  238693,\n",
       "  240446,\n",
       "  237233,\n",
       "  68652,\n",
       "  239813,\n",
       "  236392,\n",
       "  58272,\n",
       "  237533,\n",
       "  239779,\n",
       "  34103,\n",
       "  239079,\n",
       "  235248,\n",
       "  242189,\n",
       "  239449,\n",
       "  236179,\n",
       "  27941,\n",
       "  239522,\n",
       "  236432,\n",
       "  240080,\n",
       "  28693,\n",
       "  238391,\n",
       "  236179,\n",
       "  34103,\n",
       "  239079,\n",
       "  236392,\n",
       "  235248,\n",
       "  242221,\n",
       "  238994,\n",
       "  239558,\n",
       "  212174,\n",
       "  235248,\n",
       "  242394,\n",
       "  50548,\n",
       "  236179,\n",
       "  123083,\n",
       "  40284,\n",
       "  53355,\n",
       "  238036,\n",
       "  236392,\n",
       "  69225,\n",
       "  236589,\n",
       "  46355,\n",
       "  238693,\n",
       "  206716,\n",
       "  11464,\n",
       "  242127,\n",
       "  236392,\n",
       "  235248,\n",
       "  250255,\n",
       "  244866,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  236671,\n",
       "  235248,\n",
       "  240753,\n",
       "  237551,\n",
       "  236361,\n",
       "  168664,\n",
       "  235248,\n",
       "  235324,\n",
       "  235274,\n",
       "  235274,\n",
       "  235274,\n",
       "  242086,\n",
       "  237399,\n",
       "  236179,\n",
       "  123083,\n",
       "  88513,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  11464,\n",
       "  237935,\n",
       "  235248,\n",
       "  235318,\n",
       "  235310,\n",
       "  235276,\n",
       "  235310,\n",
       "  242086,\n",
       "  237399,\n",
       "  236137,\n",
       "  53355,\n",
       "  238036,\n",
       "  236392,\n",
       "  69225,\n",
       "  236589,\n",
       "  237138,\n",
       "  61943,\n",
       "  88513,\n",
       "  235265,\n",
       "  108,\n",
       "  140,\n",
       "  238146,\n",
       "  238308,\n",
       "  236361,\n",
       "  56341,\n",
       "  240080,\n",
       "  53355,\n",
       "  238036,\n",
       "  236648,\n",
       "  43761,\n",
       "  236840,\n",
       "  236361,\n",
       "  235248,\n",
       "  242269,\n",
       "  236464,\n",
       "  28693,\n",
       "  238391,\n",
       "  84551,\n",
       "  50316,\n",
       "  238325,\n",
       "  88513,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  11464,\n",
       "  185111,\n",
       "  170174,\n",
       "  17309,\n",
       "  236386,\n",
       "  236375,\n",
       "  235248,\n",
       "  235274,\n",
       "  235308,\n",
       "  237029,\n",
       "  238867,\n",
       "  236392,\n",
       "  51914,\n",
       "  236464,\n",
       "  239824,\n",
       "  239985,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  235274,\n",
       "  235276,\n",
       "  237029,\n",
       "  237598,\n",
       "  236589,\n",
       "  235248,\n",
       "  235274,\n",
       "  235315,\n",
       "  235315,\n",
       "  235284,\n",
       "  237029,\n",
       "  236179,\n",
       "  23248,\n",
       "  239465,\n",
       "  238037,\n",
       "  244908,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237045,\n",
       "  238928,\n",
       "  239457,\n",
       "  31087,\n",
       "  26801,\n",
       "  238693,\n",
       "  240446,\n",
       "  236137,\n",
       "  43761,\n",
       "  236589,\n",
       "  11464,\n",
       "  239937,\n",
       "  236645,\n",
       "  241215,\n",
       "  236214,\n",
       "  34103,\n",
       "  236554,\n",
       "  237045,\n",
       "  32090,\n",
       "  238272,\n",
       "  237502,\n",
       "  236648,\n",
       "  136201,\n",
       "  243130,\n",
       "  236183,\n",
       "  48682,\n",
       "  236039,\n",
       "  236251,\n",
       "  22803,\n",
       "  11464,\n",
       "  236791,\n",
       "  664,\n",
       "  237602,\n",
       "  239079,\n",
       "  244801,\n",
       "  153107,\n",
       "  239308,\n",
       "  236840,\n",
       "  70685,\n",
       "  236864,\n",
       "  238070,\n",
       "  236464,\n",
       "  43033,\n",
       "  236939,\n",
       "  236840,\n",
       "  50390,\n",
       "  150762,\n",
       "  116508,\n",
       "  240917,\n",
       "  236655,\n",
       "  591,\n",
       "  238582,\n",
       "  239813,\n",
       "  235832,\n",
       "  235275,\n",
       "  127637,\n",
       "  239199,\n",
       "  236392,\n",
       "  210976,\n",
       "  240080,\n",
       "  27941,\n",
       "  239158,\n",
       "  236179,\n",
       "  128856,\n",
       "  246290,\n",
       "  241155,\n",
       "  113585,\n",
       "  134498,\n",
       "  236655,\n",
       "  239956,\n",
       "  235248,\n",
       "  247776,\n",
       "  241377,\n",
       "  237233,\n",
       "  236840,\n",
       "  132929,\n",
       "  17309,\n",
       "  239056,\n",
       "  235281,\n",
       "  235832,\n",
       "  236950,\n",
       "  84961,\n",
       "  236464,\n",
       "  88513,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236361,\n",
       "  84815,\n",
       "  236569,\n",
       "  171066,\n",
       "  236864,\n",
       "  22803,\n",
       "  23745,\n",
       "  239385,\n",
       "  27941,\n",
       "  237935,\n",
       "  236179,\n",
       "  46355,\n",
       "  238693,\n",
       "  237935,\n",
       "  236589,\n",
       "  53355,\n",
       "  238036,\n",
       "  235832,\n",
       "  69581,\n",
       "  238986,\n",
       "  664,\n",
       "  237392,\n",
       "  236939,\n",
       "  236214,\n",
       "  46355,\n",
       "  238693,\n",
       "  1581,\n",
       "  156539,\n",
       "  155280,\n",
       "  238365,\n",
       "  239720,\n",
       "  241513,\n",
       "  236137,\n",
       "  235248,\n",
       "  240498,\n",
       "  237889,\n",
       "  238780,\n",
       "  235832,\n",
       "  236950,\n",
       "  235281,\n",
       "  235832,\n",
       "  236950,\n",
       "  235248,\n",
       "  238267,\n",
       "  240080,\n",
       "  72163,\n",
       "  236648,\n",
       "  46355,\n",
       "  238356,\n",
       "  236770,\n",
       "  236361,\n",
       "  235248,\n",
       "  244908,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  235303,\n",
       "  237199,\n",
       "  237759,\n",
       "  236645,\n",
       "  53355,\n",
       "  238036,\n",
       "  238080,\n",
       "  236589,\n",
       "  17309,\n",
       "  239056,\n",
       "  235303,\n",
       "  22618,\n",
       "  236417,\n",
       "  156974,\n",
       "  237433,\n",
       "  23594,\n",
       "  243320,\n",
       "  26291,\n",
       "  93828,\n",
       "  95165,\n",
       "  236137,\n",
       "  171066,\n",
       "  237908,\n",
       "  237092,\n",
       "  60318,\n",
       "  237956,\n",
       "  235832,\n",
       "  43033,\n",
       "  239574,\n",
       "  244908,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  140,\n",
       "  235281,\n",
       "  240265,\n",
       "  236915,\n",
       "  64301,\n",
       "  239574,\n",
       "  235248,\n",
       "  240115,\n",
       "  188898,\n",
       "  235281,\n",
       "  235248,\n",
       "  235324,\n",
       "  235276,\n",
       "  236800,\n",
       "  60318,\n",
       "  237759,\n",
       "  236645,\n",
       "  236137,\n",
       "  235248,\n",
       "  242475,\n",
       "  73713,\n",
       "  237302,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  82366,\n",
       "  237433,\n",
       "  236511,\n",
       "  236183,\n",
       "  235248,\n",
       "  235284,\n",
       "  237029,\n",
       "  237598,\n",
       "  236589,\n",
       "  235248,\n",
       "  235274,\n",
       "  235315,\n",
       "  235315,\n",
       "  235310,\n",
       "  237029,\n",
       "  236179,\n",
       "  235248,\n",
       "  235274,\n",
       "  235310,\n",
       "  235276,\n",
       "  242086,\n",
       "  237399,\n",
       "  236800,\n",
       "  91292,\n",
       "  237545,\n",
       "  17309,\n",
       "  150762,\n",
       "  80404,\n",
       "  239574,\n",
       "  244881,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  238928,\n",
       "  170174,\n",
       "  17309,\n",
       "  236386,\n",
       "  236375,\n",
       "  235248,\n",
       "  241330,\n",
       "  238071,\n",
       "  235248,\n",
       "  235310,\n",
       "  237029,\n",
       "  236392,\n",
       "  101260,\n",
       "  239985,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  236214,\n",
       "  235248,\n",
       "  235274,\n",
       "  235315,\n",
       "  235315,\n",
       "  235321,\n",
       "  237029,\n",
       "  154304,\n",
       "  239205,\n",
       "  240046,\n",
       "  94492,\n",
       "  236417,\n",
       "  236375,\n",
       "  235248,\n",
       "  242003,\n",
       "  238994,\n",
       "  242269,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  74860,\n",
       "  237598,\n",
       "  235248,\n",
       "  235284,\n",
       "  237029,\n",
       "  237598,\n",
       "  236589,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235276,\n",
       "  235276,\n",
       "  237029,\n",
       "  235248,\n",
       "  235284,\n",
       "  235284,\n",
       "  235276,\n",
       "  242086,\n",
       "  237399,\n",
       "  236800,\n",
       "  49061,\n",
       "  239765,\n",
       "  236817,\n",
       "  242602,\n",
       "  17309,\n",
       "  236386,\n",
       "  236375,\n",
       "  86622,\n",
       "  236039,\n",
       "  236569,\n",
       "  49061,\n",
       "  238982,\n",
       "  243960,\n",
       "  235248,\n",
       "  235274,\n",
       "  235308,\n",
       "  237029,\n",
       "  238867,\n",
       "  236392,\n",
       "  101260,\n",
       "  239985,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  236671,\n",
       "  237458,\n",
       "  48740,\n",
       "  170174,\n",
       "  17309,\n",
       "  236386,\n",
       "  236039,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  235832,\n",
       "  239805,\n",
       "  69781,\n",
       "  236864,\n",
       "  235832,\n",
       "  95622,\n",
       "  60318,\n",
       "  241215,\n",
       "  236137,\n",
       "  123722,\n",
       "  170174,\n",
       "  17309,\n",
       "  236386,\n",
       "  236214,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235274,\n",
       "  235308,\n",
       "  237029,\n",
       "  235248,\n",
       "  235274,\n",
       "  237699,\n",
       "  82366,\n",
       "  237433,\n",
       "  48060,\n",
       "  235248,\n",
       "  235324,\n",
       "  237936,\n",
       "  237699,\n",
       "  49427,\n",
       "  236179,\n",
       "  80404,\n",
       "  236183,\n",
       "  239296,\n",
       "  235248,\n",
       "  240696,\n",
       "  238356,\n",
       "  61742,\n",
       "  235265,\n",
       "  108,\n",
       "  139,\n",
       "  237199,\n",
       "  241215,\n",
       "  70471,\n",
       "  46355,\n",
       "  242903,\n",
       "  236791,\n",
       "  51914,\n",
       "  236464,\n",
       "  236511,\n",
       "  235248,\n",
       "  235274,\n",
       "  235611,\n",
       "  235284,\n",
       "  239308,\n",
       "  90869,\n",
       "  239402,\n",
       "  237199,\n",
       "  236648,\n",
       "  664,\n",
       "  237199,\n",
       "  241215,\n",
       "  236361,\n",
       "  49697,\n",
       "  238777,\n",
       "  240696,\n",
       "  242903,\n",
       "  236375,\n",
       "  106204,\n",
       "  241588,\n",
       "  239824,\n",
       "  236648,\n",
       "  31087,\n",
       "  238365,\n",
       "  235832,\n",
       "  21167,\n",
       "  236464,\n",
       "  130673,\n",
       "  240696,\n",
       "  236386,\n",
       "  238264,\n",
       "  47250,\n",
       "  236179,\n",
       "  235248,\n",
       "  240696,\n",
       "  242903,\n",
       "  236791,\n",
       "  80404,\n",
       "  239574,\n",
       "  244881,\n",
       "  236039,\n",
       "  235281,\n",
       "  236464,\n",
       "  34805,\n",
       "  237603,\n",
       "  88513,\n",
       "  235265,\n",
       "  107,\n",
       "  108,\n",
       "  106,\n",
       "  2516,\n",
       "  108,\n",
       "  180751,\n",
       "  236770,\n",
       "  73713,\n",
       "  239618,\n",
       "  235292,\n",
       "  237045,\n",
       "  238928,\n",
       "  239457,\n",
       "  35467,\n",
       "  239765,\n",
       "  236392,\n",
       "  235248,\n",
       "  244088,\n",
       "  237290,\n",
       "  238220,\n",
       "  240080,\n",
       "  777,\n",
       "  241341,\n",
       "  119312,\n",
       "  235303,\n",
       "  60318,\n",
       "  237759,\n",
       "  236645,\n",
       "  236137,\n",
       "  ...],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  ...]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "051b1bce-a444-4259-8324-615e65992f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sample_dataset = tokenized_sample_dataset.train_test_split(\n",
    "    test_size=0.1, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d256eff-17f7-4d03-99ea-c13565c3b7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['original', 'summary', 'keywords', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original', 'summary', 'keywords', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c23c3c97-c25d-4990-a231-9973ee2b5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template_ids = tokenizer.encode(\n",
    "    \"<start_of_turn>model\\n\", \n",
    "    add_special_tokens=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19557150-3da3-408d-916c-8674b6436b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template_ids, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1df8bf91-ed4a-4e43-9b6a-8cfa87268f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250807_041633-ad3qw86u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gen1004-yonsei-university/skn15/runs/ad3qw86u' target=\"_blank\">dazzling-firebrand-1</a></strong> to <a href='https://wandb.ai/gen1004-yonsei-university/skn15' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gen1004-yonsei-university/skn15' target=\"_blank\">https://wandb.ai/gen1004-yonsei-university/skn15</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gen1004-yonsei-university/skn15/runs/ad3qw86u' target=\"_blank\">https://wandb.ai/gen1004-yonsei-university/skn15/runs/ad3qw86u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gen1004-yonsei-university/skn15/runs/ad3qw86u?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f00bc491ff0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity=\"gen1004-yonsei-university\", project=\"skn15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7e52c10-5f2c-4590-a00b-4ca25481dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./keywords_gemma_results\",\n",
    "    # num_train_epochs=1, # 1epoch에 250step정도 진행함 \n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"wandb\",\n",
    "    logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "385eb013-a002-44d9-bba2-485de3a7971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "acc = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99aede04-93b5-4333-aebc-b13d926c2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # 모델과 설정에 따라 logits에는 추가적인 텐서들이 포함될 수 있습니다.\n",
    "        # 예를 들어, past_key_values 같은 것들이 있을 수 있지만,\n",
    "        # logits는 항상 첫 번째 요소입니다.\n",
    "        logits = logits[0]\n",
    "    # 토큰 ID를 얻기 위해 argmax를 수행합니다.\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds는 labels와 같은 형태를 갖습니다.\n",
    "    # preprocess_logits_for_metrics에서 argmax(-1)가 계산된 후입니다.\n",
    "    # 하지만 우리는 labels를 한 칸 이동시켜야 합니다.\n",
    "    labels = labels[:, 1:]\n",
    "    preds = preds[:, :-1]\n",
    "\n",
    "    # -100은 DataCollatorForCompletionOnlyLM에서 사용되는 \n",
    "    # ignore_index의 기본값입니다.\n",
    "    mask = labels == -100\n",
    "    # -100을 토크나이저가 디코드할 수 있는 값으로 대체합니다.\n",
    "    labels[mask] = tokenizer.pad_token_id\n",
    "    preds[mask] = tokenizer.pad_token_id\n",
    "\n",
    "    # BLEU 점수는 텍스트를 입력으로 받기 때문에,\n",
    "    # 토큰 ID에서 텍스트로 변환해야 합니다.\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    bleu_score = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # accuracy는 정수 리스트를 입력으로 받습니다.\n",
    "    # 우리는 -100이 아닌 부분만 평가하고 싶기 때문에,\n",
    "    # 마스크의 부정(~)을 사용합니다.\n",
    "    accuracy = acc.compute(predictions=preds[~mask], references=labels[~mask])\n",
    "\n",
    "    return {**bleu_score, **accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abb30ebe-22c4-49c9-b24c-cfa49ab33140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4848/854105364.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "You are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "WandbCallback\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    train_dataset=tokenized_sample_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_sample_dataset[\"test\"],\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    compute_metrics=compute_metrics,     callbacks=[WandbCallback()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afef9030-c26a-454e-8c4d-a7e14b919d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a29ebf36-d552-4b5b-a211-030425eb6d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 40:56, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.203900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.711900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.985700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.628600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.337400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.888900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.876700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.879800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=2.8920894775390624, metrics={'train_runtime': 2457.0475, 'train_samples_per_second': 2.442, 'train_steps_per_second': 1.221, 'total_flos': 7.929820002093466e+16, 'train_loss': 2.8920894775390624, 'epoch': 6.666666666666667})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8742cbcf-cdf0-4129-aaaa-87271ae64f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.290223598480225,\n",
       " 'eval_bleu': 0.07257378457364877,\n",
       " 'eval_precisions': [0.2832575607827634,\n",
       "  0.13087315991127244,\n",
       "  0.06112368800164643,\n",
       "  0.016810254255095608],\n",
       " 'eval_brevity_penalty': 0.9237953848656519,\n",
       " 'eval_length_ratio': 0.9265567765567766,\n",
       " 'eval_translation_length': 5059,\n",
       " 'eval_reference_length': 5460,\n",
       " 'eval_accuracy': 0.32876233121108234,\n",
       " 'eval_runtime': 10.4777,\n",
       " 'eval_samples_per_second': 9.544,\n",
       " 'eval_steps_per_second': 2.386,\n",
       " 'epoch': 6.666666666666667}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39813624-18cb-4450-aa26-5d2c96f87c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다. 유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다. A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려 반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다. 사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다. 사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다. 경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\n",
      "model\n",
      "\n",
      "model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다. 유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\\n11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다. A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\\n경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려 반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다. 사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다. 사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다. 경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\"\n",
    "\n",
    "def get_chat_format(input_text):\n",
    "\n",
    "        return [\n",
    "            {\"role\": \"user\", \"content\": f\"다음 텍스트를 한국어로 간단히 요약 및 관련 키워드를 추출해주세요:\\n{input_text}\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"한국어 요약:\\n키워드:\"}\n",
    "        ]\n",
    "\n",
    "\n",
    "def change_inference_chat_format(input_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "prompt = change_inference_chat_format(input_text)\n",
    "# tokenizer 초기화 및 적용t\\\n",
    "inputs = tokenizer.apply_chat_template(prompt, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_new_tokens=512, use_cache=True)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06033937-caf4-4b65-a7a6-f2bc178176ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
