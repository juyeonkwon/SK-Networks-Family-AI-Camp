{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86400fe",
   "metadata": {},
   "source": [
    "### 1. **IDF (Inverse Document Frequency)** - 단어의 희귀성\n",
    "- 검색어에 포함된 단어가 전체 문서 집합에서 얼마나 희귀한지 측정\n",
    "- 정보 가치가 높은 희귀한 단어에 더 큰 가중치 부여\n",
    "\n",
    "### 2. **TF (Term Frequency)의 정교한 활용** - 단어 빈도의 포화\n",
    "- 특정 문서에서 단어가 얼마나 자주 등장하는지\n",
    "- *TF-IDF와 달리* BM25는 이 값을 그대로 사용하지 않고 **\"단어 빈도 포화(Term-frequency saturation)\"** 개념을 도입\n",
    "\n",
    "### 3. **문서 길이 정규화 (Document Length Normalization)**\n",
    "- BM25는 문서의 길이를 고려하여 점수 보정\n",
    "- 1만 단어로 이루어진 긴 보고서보다는 100단어로 이루어진 짧은 요약문에 나오는 것이  \n",
    "해당 주제와 더 밀접한 관련이 있을 가능성이 높다는 논리를 반영  \n",
    "</br>\n",
    "---\n",
    "## BM25가 TF-IDF보다 뛰어난 점\n",
    "\n",
    "- **단어 빈도 포화**: 키워드 반복 어뷰징에 강하고, 단어 빈도의 중요성을 보다 현실적으로 모델링\n",
    "- **문서 길이 정규화**: 긴 문서가 단지 길다는 이유만으로 부당하게 높은 점수를 받는 것을 방지하여 공정한 비교 가능\n",
    "- **유연한 파라미터**: $k_1$과 $b$를 통해 데이터셋의 특성에 맞게 알고리즘을 튜닝 가능\n",
    "</br>\n",
    "---\n",
    "### k1과 b\n",
    "- **$k_1$ (Term-frequency saturation controller)**: 단어 빈도(TF)의 영향력을 조절\n",
    "    - **$k_1$ 값이 낮으면**: 단어 빈도가 조금만 높아져도 점수가 금방 포화 상태  \n",
    "    → 단어가 몇 번 나오는지보다 출현 여부 자체가 더 중요\n",
    "    - **$k_1$ 값이 높으면**: 단어 빈도가 점수에 미치는 영향이 더 커짐  \n",
    "    → 단어가 많이 나올수록 점수가 계속해서 더 많이 오름\n",
    "    - **일반적인 값**: 1.2 ~ 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c92f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "366f4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths= (\"https://news.naver.com/section/101\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"sa_text\", \"sa_item_SECTION_HEADLINE\")\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c037de",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124b6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8087b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa31b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b29f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',      # 검색 결과나 추천 목록의 **품질**과 **다양성**을 동시에 최적화하기 위한 알고리즘\n",
    "    search_kwargs={\"k\" : 1, \"fetch_k\" : 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de136bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3346789",
   "metadata": {},
   "source": [
    "#### retriever 2개를 엮어 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9e89173",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, retriever],\n",
    "                  weights=[0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "648885d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ensemble_retriever.invoke(\"오늘의 증시\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f12ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3dcd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 AI 언어 모델 조수입니다. 당신의 임무는 주어진 사용자 질문에 대해 벡터 데이터베이스에서 관련 문서를 검색할 수 있도록 다섯 가지 다른 버전을 생성하는 것입니다.\n",
    "사용자 질문에 대한 여러 관점을 생성함으로써, 거리 기반 유사성 검색의 한계를 극복하는 데 도움을 주는 것이 목표입니다.\n",
    "각 질문은 새 줄로 구분하여 제공하세요. 원본 질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4570d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(model_name=\"chatgpt-4o-latest\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x : x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14302812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cdabe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results, k=60, top_n=2):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(docs)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "   \n",
    "    reranked_results = [ (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x : x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88ae29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = generate_queries | ensemble_retriever.map() | reciprocal_rank_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "955e3b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1713/814652417.py:11: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  reranked_results = [ (loads(doc), score)\n"
     ]
    }
   ],
   "source": [
    "docs = chain.invoke(\"오늘의 증시\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "780fe368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96521d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"다음 맥락을 바탕으로 질문에 답변할 것\n",
    "{context}\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7dbb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5558884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = (\n",
    "    {\n",
    "        \"context\" : chain,\n",
    "        \"question\" : RunnablePassthrough()\n",
    "    }\n",
    "    | prompt | ChatOpenAI(model_name=\"chatgpt-4o-latest\", temperature=0)\n",
    "    | StrOutputParser()\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6434cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = final_chain.invoke(\"오늘의 증시\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "795b6a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘의 증시는 전반적으로 하락세를 보이고 있습니다.\n",
      "\n",
      "- 뉴욕증시: 미국 뉴욕증권거래소의 주요 3대 지수(다우존스 등)가 동반 하락했습니다. 이는 미국 경제의 약 70%를 차지하는 서비스업 업황이 관세 여파로 악화되었다는 소식에 따라 투자심리가 위축된 것이 주요 원인으로 분석됩니다.\n",
      "\n",
      "- 한국 증시: 미국의 관세 불확실성 재부각과 경제 지표 발표 등의 영향으로 코스피는 전일 대비 15.94포인트(0.50%) 하락한 3182.06으로 장을 시작하며 하락 출발했습니다.\n",
      "\n",
      "전반적으로 글로벌 증시는 관세 이슈와 경제 지표에 대한 우려로 인해 투자심리가 위축되며 하락세를 보이고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0e864a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"onyx\",\n",
    "    input=rt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72a34207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1713/2157980915.py:1: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"./output.mp3\")\n"
     ]
    }
   ],
   "source": [
    "response.stream_to_file(\"./output.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96614bef",
   "metadata": {},
   "source": [
    "---\n",
    "### PDF OCR로 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1693980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juyeon/miniconda3/envs/openai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dda3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_elements(path, fname):\n",
    "    return partition_pdf(\n",
    "        filename=path + fname,\n",
    "        extract_images_in_pdf=True,  # PDF에서 이미지를 추출\n",
    "        infer_table_structure=True,  # 테이블 구조를 추론\n",
    "        chunking_strategy=\"by_title\",  # 타이틀을 기준으로 텍스트를 블록으로 분할\n",
    "        max_characters=4000,  # 최대 4000자로 텍스트 블록을 제한\n",
    "        new_after_n_chars=3800,  # 3800자 이후에 새로운 블록 생성\n",
    "        combine_text_under_n_chars=2000,  # 2000자 이하의 텍스트는 결합\n",
    "        image_output_dir_path=path,  # 이미지가 저장될 경로 설정\n",
    "        languages=['kor']\n",
    "        # image_output_dir_path=os.path.join(os.getcwd(),\"figures\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716b450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = extract_pdf_elements(\"./data/\", \"face_perspective_rev4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91fa287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_elements(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    PDF에서 추출한 요소들을 테이블과 텍스트로 분류합니다.\n",
    "    raw_pdf_elements: unstructured.documents.elements 리스트\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))  # 테이블 요소를 저장\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))  # 텍스트 요소를 저장\n",
    "    return texts, tables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "texts, tables = categorize_elements(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58bb946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"제 |\\n\\n30411 0 416 (0『68 105414[6 0 101011772400 200 (0001000741110814011 609106061 ㅁ 109\\n\\n한 국 정 보 통 신 학 회 논 문지 01. 23, 30. 1: 399~406, 4182. 2019\\n\\n학습 시간 단 축 과 보안 강 화 를 위한 새로운 얼굴 인식 방식 권 주연 ㆍ 반 태 원 *\\n\\n스 88006! 『2066 【『600910100170 시 00102 07 『【<004009 1[2010 ㅁ 179 11016 8300 80609[160109 56040\\n\\n44- 토 600 6\\\\00' ㆍ 146-\\\\00 22077\\n\\n1000686804866 8640606 1260800060 0 1 300 10[060708000 0081466008, (056008580 을 피 800081 001960916, 065600808101, 52828 01768\\n\\n2427016590, 1060800060[ 0 1 800 10[0008000 0081466018, (560089808 피 040081 0701061915, (0/60080801, 52828 0068\\n\\n얼굴 인식 기 술 은 특히 00\\\\10-19 팬 데 믹 이후 비접촉 신원 의 이미지 기반 시 스 템 은 대규모 학습 데 이 터 셋 으 로 인한 유출 위 험 이라는 두 가지 주요 문 제 에 직 면 하 고 있습니다. 터 와 원근 변 환 을 활 용 한 새로운 좌표 기반 학습 방 식 을 제 안 함 니다. 얼굴 이 미 지 에서 추 출 된 에의 멘 드 마크 과 표 를 활 용 함으로써 원본 이 미 지 를 저장할 필 요 가 없어 개 인 정 보 를 보 호 하고 데이터 크 기 를 줄여 학습 속 도 를 향 상 시 렸습니다, 뜻한 원근 번 환 을 적 용 해 정 면 화 된 데 이 터 른 생 성 함으로써 다양한 각 도 와 표 정 에서도 인식 정확 험 결과, 제 안 된 시 스 템 은 기존 방 식 에 비해 학 습 시 간 을 약 68% 단 축 하 면서도 98.5% 이상의 으 로 나 타 났 습니다. 본 연 구 는 현대 생 체 인식 시 스 템 에서 안 전 하 고 효 율 적 이며 정확한 적인 해 결 책 을 제 시 합니다.\\n\\n28567' 쿄 4677\\n\\n80181 76008010070 6601200108 189 66000716 80 66960081 (001 140 00068006885 1060067 ?6011680070, 2800104182017 10110\\\\70 을 046 220512-19 580060016. 0\\\\64 ㅋ 66, ㅁ 080100081 174886@-08560 5556(6109 1806 0000 5181011108 파 이 181160868: 11911 6007041800081 00515 046 (0: 6@6(6081976 0 ㅁ 81014 081856(9 800 20786 21916 8990018160 \\\\141 660070 응 130181 1018865. 11115 5040 10000040668 80061 0007010816-08560 16800108 800008011 04181 169608868 18001048 대 0818 800 206660600176 6805101701860070 (0 8007659 01666 195468. 13? 4510 음 68 18000080 00070108[66 6%080160 17001 130181 1018865, 0416 0『0]00560 0100100 이 101108168 416 0060 (0 66076 78\\\\ 1018868, 4148 58168481010 용 26050081 0813 800 760040108 0818 5120 10『 139667 60 ㅁ 810108. 『0669060076 0 ㅁ 810510110811070 147016『 0011840065 76008010070 8000780 07 6060800 음 10006811200 0818, 120070\\\\10 을 26000008006 107 0176796 80 인 66 800 6%[0765510708. 0[06014460181 7694166 06104070517816 0418[ 016 27000560 5796610 8 이 4665 8 481010 응 4046 760400100 01 8000034148617 68% 000008760 (0 6006000081 041601005 \\\\1116 01810681010 응 06 98.5% 83000180. 11118 5040 200650019 80 01[600196 501041100 107 560416, 0[1101606, 800 800417866 18181 7000801000 10 1000610 10101060000 99661008.\\n\\n키워드 : 얼 굴 식별, 덤 러닝, 좌표, 원근 변환, 학 습 시간 란 , 의\\n\\n670\\\\0/0006 : 8406 100001168000, 00070 16800108, 0007010866, 06692060006 0 ㅁ 805[0101, ㅁ 811014 을 4146\\n\\n표 6601760 29 80081 2019, 표 61560 29 18701. 2019, 스 0660060 21 001 2019 추 (@00690000108 04010 186-\\\\00 880(6-04811:04008035(0/204.80.10. 1 이 :+82-55-992-9177): 20016560『, 10608007060[ 01 스 1 800 1010008000 0810466008, (0076008584 을 페 600081 001067916, 41014, 52828 0768\",\n",
       " '100://001.09/10.6109/10106.2019.23.1.399\\n\\n민 594:2234-4772\\n\\n(697016 5 40 0060 66655 204616 0160160060 40067 006 16005 0 006 6@668046 060040005 7000150008. 00-000400666101 1.16605004003006600006000401005.08/017660506 169-0673.07) 4404 0660466 4066566660 000-60090460121.056, 0166164008, 400 760600460070.10 809 0460149 06041060 006 0081081100616 0000605 0060. (200347846 (6) 7416 60668 10900466 0 10109600480020. 800 (0000440168000 620 용 14166000 을 .\\n\\n최근, 다양한 신원 확인 기 술 들이 빠르게 발 전 하고 있다. 과 거 에는 비 밀 번 호 나 카 드 와 같은 인증 방 식 이 주로 사 용 되 었지만, 위 변 조 나 문 실 의 위 험 으로 인해 신 뢰 성 있는 대 안 이 필 요 해 졌다 [1]. 이러한 배 경 에서, 지 문 , 홍채, 음성, 그리고 얼굴 등 을 활 용 하는 다양한 생체 인식 기 술 들 이 주 목 받기 시 작 했으며, 지 문 과 얼굴 인식 기 반 의 신원 확인 기 술 은 간편한 처리 과 정 과 낮은 복 잡 성 으로 주 목 받고 있다 [1]. 특히, 코 로 나 19 팬 데 믹 을 거 치 면 서 전염병 확 산 을 차단할 수 있는 비접촉 생 체 인 식 기 술 에 대한 수 요 가 금 증 하고 있다 [2~51.\\n\\n비접촉 생 체 인식 기 술 에는 홍채, 정맥, 그리고 얼굴 등 이 사용될 수 있다. 홍채 인식 기 술 은 사 람 마다 고유 한 홍채 패 턴 을 활 용 하여 높은 정 확 도 를 제 공 할 수 있 지만, 고해상도 카 메 라 가 필 요 하고 홍 채 와 카메라 사이 의 거 리 가 증 가 함에 따라서 인 식 률 이 급격히 저 하 되는 문 제 점 을 가진다 [2]. 정맥 인식 기 술 은 손 이나 손 목 의 정맥 패 턴 을 활 용 하는 방 식 으로 위 조 에 강 하 다 는 장점 이 있지만, 전용 기 기 가 필 요 하여 높은 비 용 이 소 요 되 어 민간 영 역 에서 활 용 되기 쉽지 않다 [1].\\n\\n반 면 에, 얼굴 인식 기 술 은 원 거 리 에서도 신 원 을 정확 하고 빠르게 확인할 수 있으며 [3], 최근 닙 러 닝 의 발전 으로 정 확 도 가 비 약 적 으로 발 전 하면서 공항, 금융 기관, 공공 기 관 뿐만 아 니 라 [4, 5], 개인용 스마트 디바이스 및 가정용 보안 장 치 에서도 활발히 도 입 되고 있다. 마 트 폰 잠금 해제, 가정용 출입 보안 시스템 등 다양한 개인 환 경 에서도 얼굴 인 식 이 보 편 화 되고 있으며, 이는 높은 편 의 성 과 사용자 경 험 을 제 공 한다.\\n\\n개인 환 경 에 서 의 얼굴 인 식 은 사 용 자 에게 추가적인 행 동 을 요 구 하지 않아 편 리 성 이 높을 뿐만 아니라, 별 도의 전용 장 비 를 요 구 하지 않으므로 기존 감시 시스템 이나 모바일 기기 등 다양한 플 랫 폼 에서 쉽게 구 현 될 수 있다 [1].\\n\\n덤 러닝 기 술 의 발 전 으로 힘 입어 얼굴 인식 기 술 의 정 확 도가 비 약 적 으로 높 아 졌 지만, 대규모 얼굴 이 미 지 에 대한 학 습 으로 인해 신경망 학습 및 추론 과 정 에서 계 산 량이 급격히 증 가 한 다. 또한, 새로운 구 성 원 의 추가 를 위한 학습 시 에 기존 구 성 원 들 에 대한 망 각 을 방지 하기 위하여 지속적인 추가 학 습 이 필 요 하고, 이를 위 기존 학습 데 이 터 를 지 속 적 으로 보관할 필 요 가 있\\n\\n『6804@ | 6608 에 00 10600668000 7060068800 마타 만 00655109\\n\\n19. 1 『8 이 리 (600901400 56161 하 아 11601416 08560 00 0660 06 나 히 06[\\\\4000<5.\\n\\n_\\n\\n나 [67].\\n\\n얼굴 인중 시 스 템 에서 저장된 얼굴 데 이 터 는 개 인 의 생체 정 보 가 포 함 된 민감한 데 이 터 로, 유 출 로 인한 심 가한 보안 위협 문 제 가 상 존 한다 [8]. 개인용 기기 의경 우 분실 및 해 킹 으로 인한 데이터 유출 시 사용자 신 이 직 접 적 으로 노 출 될 위 험 이 있으며, 일부 보안 24 을 적 용 해 얼굴 데 이 터 를 변 환 하여 저 장 하더라도, 다양 한 복원 기 술 을 활 용 하면 원본 얼굴 이 미 지 가 재 구 성 될 가 능 성 이 존 재 한 다 [9]. 이는 단순한 보안 문 제 를 넘 님 페 이크 생성 등 의 악용 가 능 성 도 내 포 한다 .\\n\\n.\\n\\n이를 해 결 하기 위해 인위적인 노이즈 삽입 기술 등 이 연 구 되고 있으나 [10], 변 환 된 데이터 역시 복원 가능성 이 존 재 하기 때문에 근 원 적 인 해 결 책 으 로 는 부 족 하다.\\n\\n메타 ( 페 이 스 북 ) 의 \"048 9488660009 0『08180\" 사 례 는 이러한 개 인 정보 유출 문 제 를 극 명 히 보여준다. 메 타 는 사용자 동의 없이 수 집 한 안면 인식 정 보 를 처 리 하다가 110076010 1010008400 00180 ㅅ ^0 (8124) 위 반 으로 소 송 에 휘 말 렸 으며, 2020 년 7 월 6 억 5 천 만 달 러 를 지 금 하 사 건 을 종 결 지었다 [111. 이는 원본 데 이 터 를 저 장 하 거나 처 리 하는 시 스 템 이 초래할 수 있는 보안 및 프라 이버\\n\\n스며\\n\\n_\\n\\n인 할 기 ㅁ ㅣ\\n\\n_\\n\\n이를 위해 본 연 구 에서는 016 [12] 를 이 용 하 여 얼굴 이 미 지 로부터 주 줄 된 68 개 의 주요 렌 드 마크 좌표 [131 을 주 줄 하여 학 습 과 주 몬 에 활 용 하였다. 특징 좌 표 를 임 력 으로 사 용 하면 선형 모 연 산 량 을 줄일 수 있으며, 원본 얼굴 이 미 지 를 저 장 하지 않기 때문에 개 인 정보 보호 측 면 에서도 안 전 하 다.\\n\\n또한, 추 출 된 특징 좌 표 들 에 원근 변환 (06690600\\\\6\\n\\n1004 『 ㅁ 「6-「006055109 『6「6060076 | 7780610107 1591 고 『681416 ㅁ 『806 (0600「010816 2592 페 2002 | > 20006 > ㅁ 2616 예 00 - 2908 세 0078 70000 608 예 100 : : 200 0 20 고 ~, 2 205 60008 에 00 이 72 00061 0080) 0135511081100 『680416 000「01081[65 + (256. 128) 01365(0) 『『00. (128. 64) 7000(1) 0.03 터 34660 7 호 터 . 띠 000081126 개 8 1 0 0418(2) 0.22 더 벌 으 그 개 | 1 202 본 | 2 || ㅋ | 5 : : 더 떠 설 11 ㆍ ㆍ 므 더 더 860 (() _0.16 로 6 (2722. 1) (64. () 『4114 ㅁ 000060060 130615\\n\\n19. 2 『『『000500 하 아 11601416 08560 070 0660 1064181 06000 107 1306 01855611081100.\\n\\n6805[00080070) [14] 을 적 용 하여 다양한 얼굴 각 도 와 표 정 변 화 에 따라서 얼굴 인식 정 확 도 를 높이기 위한 새 로운 기 법 도 제 안 한 다.\\n\\n실제 환 경 을 고 려 하여 신 경 망 을 학 습 하고 추 론 한 결 과 에 따르면 제안 방 식 은 기존 방식 대비 약 99% 의 확 도 를 확 보 하면서 평균 학 습 시 간 을 약 68% 단 축 시킬” 수 있다, 본 논 문 의 구 성 은 다 음 과 같다. 1 장 에서 제안 하는 시스템 모 델 을 자세히 설 명 하고, 1 장 에서 몬 구 에서 제 안 하는 새로운 얼굴 인식 학습 방 법 을 기 술 한 다. 14 장 에서 제안 방 식 의 성 능 을 분 석 하고 이를 기존 기 술 과 비 교 한다. 마 지 막 으로, \\\\ 장 에서 본 논 문 의 결론 을 맺는',\n",
       " '사 람 의 얼굴 영 역 을 탐 지 하고 추 출 한 다. 주로 180 0890806, 00 (81960081801 0【 0 ㅁ 60160 (378016019), 41644 (05400410-686 (608868060 (0000701000081 제 600006) 과 같은 기 법 이 사 용 된 다. 주 출 된 얼굴 영역 신경망 모 델 에 적 합 하도록 전처리 과 정 을 거친다. 이미지 크기 변환, 정렬, 조명 보정 등 다양한 작 업 이 포 함 되며, 이를 동해 다양한 환 경 에서도 모 델 이 안 정 적 으 작 동 할 수 있도록 한다. 특히 표 준 화 를 동해 데이터 의 일 관 성 을 유 지 하며, 이는 시 스 템 의 인식 성 능 을 크 게 향 상 시키는 핵심 과 정 이다. 최 근 에는, 데 이 터 셋 의 효율성 향 상 을 위하여 이미지 증강 (10886 스 080060180020) 과 정 도 널리 활 용 되고 있다.\\n\\n정은\\n\\n연로\\n\\n. 시스템 모델\\n\\n그림 1 은 본 논 문 에서 다루는 심화 신경망 기반 얼굴 인식 시 스 템 의 전반적인 구 조 를 나타낸다. 얼굴 인식 시 스 템 은 입 력 된 얼굴 이 미 지 로부터 신 원 을 확 인 하기 위한 일 련 의 과 정 으로 구 성 되며, 먼저 입 력 된 이 미 지 로 부 터 의 얼굴 감지, 전처리, 특징 추출, 신원 확 인 의 | 가지 주요 단 계 를 포 함 한 다. 먼저, 이 미 지 나 영 상 에서\\n\\nㆍ\\n\\n특징 추출 과 정 은 얼굴 인 식 의 핵심 단 계 로, 심화 신 경 망 모 델 을 이 용 하 여 얼굴 이 미 지 를 고 유 한 특징 벡터 로 수치 변 환 하는 작 업 이다. 일 반 적 으로 0844 (000\\\\01400081 8060781 4060\\\\000) 모 델 이 널리 사 용 되 며 , 이 모 템 은 눈 , 코 , 입 둥 시각적 패 턴 을 학 습 하여 얼 굴 을 그 차원 벡 터 로 표 현 한 다. 마 지 막 으로, 신원 확인 단거 에서는 추 출 된 특징 벡 터 를 이 용 하 여 입력 이 미 지 의 신 윈 을 확 률 적 으 로 추 정 하며, 줄임 또는 접근 제 어 와 같 은 실제 응용 서 비 스 에서 활 용 된다.\\n\\n한 국 정 보 통 신 학 회 논문지 01. 23, 800. 1: 399~406, 4180. 2019\\n\\n78016 1. 『『\"21230761676 10 ㅁ 06「50600146 1『2806[017 10 176 ㅁ 0「000560 50116076\\n\\n옥 040666 7818665 1 (210 919) 00005 수 0) 3 (226 920) 0000~ 우 0) (6206 060) 00006 드 1000) 3 (6010 310) 007726070/0]\\n\\n0 그 즈 벼 때 \" 2 \" 콜 2 웨 { 리 운 8% 보 > 수 쁘\\n\\n미 지 로 부터 된 68×?3 크 기 를 3 차 원 픽셀 더 이드 구성된 얼굴 이미지 를 사 용 하는 기존 방 식 들 에 비해서 신경망 입력 데 이 터 의 크 기 를 획 7 글 적 으 로 줄일 수 있다. 이를 통해서, 기존 얼굴 인식 시 스 템 에서 널리 사 용 되 는 600 ㅁ 01400081 계 충 을 단순한 선형 계 중으로 대 체 할 수 있다. 또한, 학습 얼굴 이 ㅁ 완료된 후, 원본 얼굴 이미지 대 신 에 굴 이 미 지 로의 역 변 환 이 불가능한 68 개 의 좌표 데 ㅇ 개 인 정보 유출 문 제 를 해결할 수 있 고, 저장 용 량 도 낮출 수 있다. 지 크기 및 해 상 도 에 관 계 없이 안정적인 학 습 이 가 능 하 다. ㄷ 으 무 10 고 쑤 00 원 1 ㅁ 파 곡\\n\\n또한, 그림 2 에 서 보는 바와 같이 제안 방 식 에서는 추 출 된 68 개 의 각 도 와 표정 토이 다 에 은 으 녀 ) 뽀 , 에 1 @ 떠 때 00 [월 493 / 자 따오 띠 0 | 픈 [원 006 후 으 띠 분 1 ㅇ 홍조 주 \" 뿐 프 2 입으 븐 | ㅇ 미 오보 1 ㅇ 1! 으 머 동우 6 을 & 근 | 조 뿌 0 06 66 띠 2886 모 @ 개 ㅁㅁ ㅋ 0 근 변 의 미 지 이 10, 19, 그리고 24 랜 드 마크 차 을 사 용 하며, 각 랜 드 마 크 좌 표 의 목표 지 점 들은 표 [에서 제시된 바와 같이 이 미 지 의 가 로 와 세로 길 이 에 대한 비 율 로 결 정 된 다. 제안 시스템 의 신경망 모 델 은 네 개의 완전 연 결 중 (80015 1 으 파 뽀뽀 떠\\n\\n78016 2. 『2「2010616「6 10『 9101413811078.\\n\\n프 2080006065 도 31466 제 410666 0 이 898656 ( 2) 5 10041 5120 68×2 (136) 38601 5126 128 00005 1000 브 6800108 2066 (070) 10 . 옥 660 1680010 을 186 (5660. 5126=10, 1.6800108 10866 5011604166 8800018=0.5) 00002 스 0800 (\\\\ 히 1 06089=10 7) 1.098 (20065 6000005 1200004100060816011155 04 께 000481128000 91800070120000 (2-500[6) 스 60008057 0 1000 6827 999 16000108000 0 1680010 응 .\\n\\n(0200060660 ㄴ 8560) 으 로 구 성 되며, 각 완전 연 형 계층, 데이터 정 규 화 를 위한 배치 고 위한 76000660 10687 401 (8610), 가 키 한 합 브 확률 0.4 의 000004 함 수 로 이루 드 수 는 각각 512, 256, 128, 그리고 6 64 로 완전 연 결 층 에 의해서 추 출 된 64 개 의 78106) 은 마지막 분 규 기와 801 50108 화적 래 스 에 대한 확률 값 들 로 출 력 된다. 이 용 하 여 식 (1) 과 같이 교차 엔 트 로 피 를 배너 의 한 다.\\n\\n1.2= 27 6 10800) 0)\\n\\n《 와 /,, 는 클래스 7 의 이진 레이블 값 과 508106% 출력 확률 값 을 각각 내고, 손 실 한 수 를 최 소 화 하기 경 사 하강 법 으로 모 델 의 매 개 변 수 들을 지 속 적 으로 업 데 이 트 한 다\\n\\n0 =0-/ 으 은 (2)\\n\\n와 /7 은 각각 신경망 모 델 의 매 개 변 수 와 학 습 률 을 의 미 한다.\\n\\nㅡ 000 \\\\/0 0. 0800510000. 1.50 ㅡ 0100 \\\\/ ㅁ . 0800510007. - ㅡ - 00 2 떠 83100 더 든 0.75 닉 _ 51 0.25 0.00 6000008067006.6600009 000 (3) 00055 60000) 1065. 때 0.8 06 티 오 0.4 50 60 0.2 ㅡ 000 \\\\/0 0. 00051007. - ㅡ 0000 \\\\/ 0. 00050. 때 - ㅡ - 004 50 100 150 200 250 300 70016 (5200005) (6) 46041080. | 6 0916 |. 0. 000 0.995 0.990 000 0000 0098 10000 0.985\\n\\n-0.980\\n\\n0.9901\\n\\n0.9900\\n\\n1 1: !\\n\\n00605900 06001 쓰 6001000\\n\\n40.606\\n\\n(0) 16800800-\\n\\n19. 3 『『\"60011181706 00000811600 0 116 0『0005600 800 0006010081 6017607165.\\n\\n정은 신경망 모 델 의 학습, 평 7 가, 그리고 시 험 의 세 과정 으로 구 성 되며, 매 에 포크 학습 후 모 델 의 성능 을 평가\\n\\n하고 조기 종료 조 건 을 만 족 하면 학 습 을 종 료 하고 모델 때 뻔 0 의 성 ㅇ 을 최종 시 험 한다. 각 클 클 래 스 별 로 총 1.000 샘플 을 활 용 하였으며 학습, 평가, 그리고 시험 과 정 에서 ㅅ 버 용 되는 샘 플 의 비 율 은 @:111 로 설 정 하였다.',\n",
       " '성능 평 가 는 정확도 (&0004808005), 정밀도 ( ㅁ 576019100), 재 현 율 (《6081), 18156 009116 1866 (67), 그리고 13166 7688076 1786 (0848) 등 의 주요 지 표 를 기 준 으로 수 행 히 였으며, 각 지 표 들은 식 (3)~(7) 에 서 정 의 된다. 또한, 주 어진 8 값 에 대한 #6081 값 으 로 이루어진 곡 선 인 760616『 00668018 01818 이 60500 00006 (《00() 의 밑 면 적 을 나타내는 008 00060800(&0_000) 도 분 석 하였다.\\n\\n이러한 성능 분석 결 과 를 기존 방 식 과 비 교 하 였다. 기존 방 식 에서는 원본 이 미 지 를 직접 활 용 하여 신경망 을 학 습 시키는 방 범 이 사 용 되 었으며, 대표적인 이미지 식별 모 델 인 #69466-101 을 적 용 하였다. 반면, 제안 방 식은 이 미 지 의 특정 특 징 을 보 완 하는 기 법 을 도 입 하여 성 능 을 개 선 하고자 하였다.\\n\\n표 2 는 성능 분 석 을 위한 시 뮬 레 이 션 에 사 용 된 구 처 적인 파 라 미 터 들 과 값 들 을 보여준다.\\n\\n7022+ 71 60000 701 70 007 시 미\\n\\n000 72 200015100 = 70724 222 0\\n\\n72 60001= ㅠㅠ (65) 72+27\\n\\n222 = 6 20224 2717 00)\\n\\n= 200 태 &= 70241 2767 0\\n\\n그림 3-(8) 는 원근 변환 적용 여 부 에 따라 두 방 식 으 로 구 분 된 제안 방 식 과 기존 방 식 의 하 학습 동안 관 측 된 힌 을 적 만 방 식 이 시간 대비 학 학습 속도 및 효율성 측면 가장 우 수 함 을 알 수 수 있으며, 기존 바 식은 입력 이미지 의 많은 데이터 크 기 와 그에 따른 신경망 꼬 델 의 높은 복 잡 도 로 인하여 학습 속 도 의 안 정 화 에 많은 시 간 을 필 요로 한다. 구 체 적 으로, 학습 손 실 이 0.25 에 이 르 기 까지 기존 방 식 은 제안 방식 대비 약 3 배 이상의 학 습 시 간 을\\n\\n요 구 한다.\\n\\n그림 3-06) 는 신 다 진 행 한 신경망 5 제안 방 식 은 원 식은 90% 의 정확: 간이 필 요 함 을 알 수 @ 시 와 미적용 시 에 46 초 와 달 성 하는 반면, 기존 방 75 초 의 학 습 시\\n\\n그림 3-(0) 는 세 6091, 그러고 40 보여준다. 먼저, 원근 지 표 에서 가장 우 수 현 그 점 수 가 미 미 하게 하 락 하는 것 델 의 ㅅ 06000800, 206019100, 하여 평 가 한 히 트 맵 을 비 그리고 #6091 에 서\\n\\n묘 ( ㅁ 조 때 모티 호 ㅇ 6 구우 후 (0 위 피 뚜 시 에 고 00 5 쏘 ㅇ 6 여 ㅁ 삐 | > > 조 1: 문 쁘 고 의 10 010 00 표 데 이 터 를 활 용 한 출 위 험 을 완벽히 제 조 ! ㅣ 0 오 삐 은 (은 띠 0 ^ 9 10 뚜 으 때 기 원 피 프 ㅇ 녀 > 8 삐 꾼 피 00 그 0 [ 리 8 ㅠ 파 버 다 ( 앙 에 기 기 고 으 을 ㅋ 30 쏘 29 38 위 [> = 모 건 개 0 요 으 왼 뚜 그 기 8 피 띠 0 {6 맨 을 우 을 : 고 비 00 이 웨 ※8 운\\n\\n근 변 환 적용 시외 습 으로 90% 이상 은 90% 의 정 확 도 를 듣 요 하 였다. 학 습 이 윈 과 에 따르면, 원근 ~ 위 표 에서 가장 우수한 성능 근 변환 없이도 ! 0 62 이 > ㅇㅇ (90 읍 더 년 다 5 [0 없 , 개 으 그 저 [0 8 서 뚜 16 ㅇ 떠 뜨 2 후 86 으 피 9 [우프 을 {( { 뚜 기 06 운 나 에 에 ㅇㅇ 으 쓰 패 구 처\\n\\n안정적인 성 능 을 보이지만, 4004080/, 『76019100, 그리 고 &6001 에 서 점 수 가 미 미 하 게 낮아진다.\\n\\n이러한 결 과 는 제 안 된 좌표 기반 학습 방 식 이 기존 신경망 기반 시 스 템 의 학습 속도 문 제 를 해 결 하는 동시에, 높은 인식 성 능 과 보 안 성 을 유지할 수 있 음 을 설 험 증 한 것이다. 뜨 한, 원근 변 환 을 추가적으로 써 다양한 얼굴 각 도 에서도 안 정 적 인 인식 성 능 을 확 보 할 수 있 음 을 확 인 하 였 디\\n\\n본 연 구 의 인용 스마트 디 비 이스, 가정용 보안 시스템 } 원 이 제한된 환 경 에서도 높은 신 뢰 도 를 유지할 수 있는 경 량 화 된 얼굴 인식 기 술 의 가 능 성 을 제 시 한다. 향후 연 구 에서는 실제 하드웨어 환 경 에 서 의 최 적 화 된 구 현 을 동해 제안 방 식 의 실 용 성 을 더욱 강 화 하는 방 향 으로 확 장 할 수 있을 것이다.',\n",
       " '대 어 밀 머 메 머 민 허 08\\n\\n1] 1. &. 00865 \\\\. 2. 5608, 800 ^. 66891. \"^ 176\\\\6\\\\ 0 161000 이 046 160000108 ㅋ 86100 을 1\\\\001 66008 800 1000506066,\" 2207070777 200087007007, 901. 47, 00. 8, 02. 2673-2688, 2014. 20: 10.10160.080608.2014.01.016\\n\\n21 1... 60. 7. 브 . 81, 800 1060 5600067 66680 860786070. 스 760100108166 66008 107 1045 76008010600 86 8 01968006,\" 고 /0600710707765 0770 76/600772077107700770775 776/248, 5701. 28, 00. 3, 20. 67-70. 7000. 2013. 001: 10.226487/877<1.2013.1.280308.\\n\\n브 . 4. 41000 800 5. 82. 2820, \"1116 1104-68560 100 01568006 1866 1600801400 4510 10410116 01968006 1806 10886 800 떠 161110668『 10660001860020,\" 7776 2/000770/ 0/\\' 07607 7075707006 0/\\' 207077070707077 786007070/081. 701. 11, 00. 3, 02. 95-101, 2013. 1001: 10.14801\\n\\n[4] . 240, ㄴ \\\\808, \\' 때 685101416 5040 이 86 706\\\\ 56004060 601168000 0000685 08560 00 1306 7600801000 6601001085 0 10000) 20207707 07 /7019769- (000276/60006 56769, 101. 1510,\\n\\n720. 1, 20 1225, 487. 2020. 1001: 10.1088/1742-6596/1510717012025\\n\\n[5] 6. 8148, 6. 540418659066. 800 스 . ^1-^7811. [086502060[ 575[6005 28560 00 7806 \\\\6008010070: ^ 54006, 020007000 0\" (22000/000700705 7.056/, 701. 41, 00. 5, 00. 563-571, 48. 2022. 001: 10050086.2022.05.70\\n\\n[이 테 551. 28560, 541. 516670-01046062, 씨 . 6411, (\\'. 587202010, 800 토 . 시 18682, \"5900-(0-600 1406661060681 16800108, ) 777006600788 0/\" 17076 41010727007 (007270700700 07 (007020061 14907 (4077. 0 ㅁ ㅠㅠ 233-248, 2018. 001: 10.48550787304.1807.09536\\n\\n[7] 9. ^. 860000, ^. 토 이 6601460 모 6. 5060, 600 :. 브 . 1800060\\n\\n이 (281.: 146760460681 이 4651116『 800 760『666068000 16800108, 20000000788 0/ 206 74400 (70776700700 0/ (000702006/7 17970 070 -70077077 766008707007007 ((770400, 20. 2001-2010, 2017. 1001: 10.48550787%17.1611.07725\\n\\n[18] 5. 브 . 166, -\\'460001016 8860 207 01007600450060 (3691 아 16660660040 응 ,) 2060770/- 0/\" /7010022602 (0007900007070/ 2500076$, 70. 42, 20. 375-405, 2023. 12001: 10.21592/76401.2023.42.375\\n\\n[91 튜 . 9. 612, 1. 6808, ㅁ . 브 . 제 97808, 800 <. 브 . 166, \"7116 56000 200501620 00815515 107 16?669101167 0 0 ㅁ 8051000060 16100060046 10+0008000 088 00 이 8606060『-08560 1806 8400160008000,” 270007207/ 07. 2746 ㅅ 0760 - 7079070406 0\" 207077700707 .560007020 &@ (7)7270708. 101. 18, 00. 3. 02 51-59, 2008. 001: 10.13089/71119(\\'.2008.18.3.51\\n\\n10] 6. 9. 166 800 8. 브 . 120, \"048 768100 0089008 68560 00 16100008 1600201046,\" 507077 240070 2010770/, ㅋ 701. 11, 00. 2, 20. 25-30, 2022. 1001: 10.306937911.2022.11.2.25\\n\\n11] 1. 800165, 08661. 660006, 1046.: 1116 601160000, 5607886, 800 0456 0[ 61000460406 0818 85 8 6000606 10141 40066 810.\" (00706 0076 (/472720050072 4010 01766. 9701. 50, 00. 1, 801. 9, 20. 61-72, 4406 2020.\\n\\n12] 2. 8. 6108, \"01160: ^ 20800106 16800108 10010\" 776 20007707/ 07\" 20000076 /.607772078 69600, 1701. 10, 0 ㅁ - 1755-1758, 2009. 1001: 10.1145/1577069.1755843\\n\\n13] 보 . \\\\4 800 0. 01, “78081 1400108 다 06(600010: 스 1166080176 54176) 7027077707707707 270107707 07/\\'(7007020076/: 12900. 701. 127, 700.2,700. 115-142, 2019. 001: 10.10077/611263-018-1097-2\\n\\n14] 줘 . 60, 스 . 00102, 2. ^0010723, 800 (0. ^0401004, 066690600176 0 ㅁ 805[00018000 18566,\" 770066000788 0/ 746 2022 2070777077070/ (70276760706 002 \\'(007020007070707 .5070607006 000 (7000207007070/ 7776/0760000 ((567), 00. 1395-1401, 1060. 14-16, 2022. 001: 10.48550787301.2201.05706',\n",
       " '권 주 연 (]14- ㅜ 600 \\\\00)\\n\\n2021 년 3 월 ~ 경 상 국 립 대 학교 &1 정 보 공학과 학사\\n\\n:\\n\\n※ 관 심 분야 위 성 통신, 마 이 크 로 과 회 로 해석 및 설계, 계 측 제 어 ( 본 문 과 같이\\n\\n|\\n\\n」|\\n\\n반 태원 (186-\\\\004 830)\\n\\n1998 년 3 월 경 북 대 학교 전 자 공학과 학사 2000 년 월 경 북 대 학교 전 자 공학과 석사 2010 년 2 월 4157 전 기 및 전 자 공학과 박사 2000 년 3 월 ~ 2013 년 8 월 7 네 트 위크 부문 2012 년 9 월 ~ 현재 경 상 국 립 대 학교 씨 정 보 공학과\\n\\n교수\\n\\n유 ※ 관 심 분야 : 이 동 통신, 자 원 관 리 , 간 섭 관리, 협력 및 중 계 통신, 인 지 통신, 주 과수 공 차세대 이 도 ㅎ 토 ㅎ 신 시스 템 만']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24552f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9bb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_texts = \" \".join(texts)\n",
    "text_token = text_splitter.split_text(joined_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e94549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c93444f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "당신은 표와 텍스트를 요약하여 검색에 활용할 수 있도록 도와주는 도우미입니다.\n",
    "이 요약본들은 임베딩되어 원본 텍스트나 표 요소를 검색하는데 사용될 것입니다.\n",
    "주어진 표나 텍스트의 내용을 검색에 최적화된 간결한 요약으로 작성하세요.\n",
    "요약할 표 또는 텍스트 : {element}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9699985",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3fdf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name=\"chatgpt-4o-latest\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c2c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_chain = (\n",
    "    {\n",
    "        'element' : lambda x : x\n",
    "    }\n",
    "    | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "text_summaries = summaries_chain.batch(texts, {'max_concurrency' : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51add85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['요약:  \\n'\n",
      " '본 논문은 얼굴 인식 기술에서 학습 시간 단축과 개인정보 보호를 동시에 달성하기 위한 새로운 좌표 기반 학습 방식을 제안한다. 원근 '\n",
      " '변환과 얼굴 랜드마크를 활용하여 원본 이미지를 저장하지 않고도 정면화된 데이터를 생성함으로써 다양한 각도와 표정에서도 높은 인식 정확도를 '\n",
      " '유지한다. 제안된 방식은 기존 대비 약 68%의 학습 시간 단축과 98.5% 이상의 인식 정확도를 달성하였다. 이는 비접촉 생체 인식 '\n",
      " '시스템의 보안성과 효율성을 향상시키는 효과적인 방법으로 평가된다.\\n'\n",
      " '\\n'\n",
      " '키워드: 얼굴 인식, 딥러닝, 좌표 기반 학습, 원근 변환, 학습 시간 단축, 개인정보 보호.',\n",
      " '요약:  \\n'\n",
      " '본 논문은 얼굴 인식 기술의 정확도 향상과 개인정보 보호를 동시에 달성하기 위한 새로운 접근법을 제안한다. 기존 얼굴 인식 기술은 높은 '\n",
      " '정확도를 제공하지만, 원본 이미지 저장으로 인한 개인정보 유출 위험이 존재한다. 이를 해결하기 위해 본 연구는 얼굴 이미지에서 추출한 '\n",
      " '68개 랜드마크 좌표를 입력으로 사용하여 원본 이미지 저장 없이 인식이 가능하도록 하였다. 또한, 원근 변환을 적용해 다양한 얼굴 각도와 '\n",
      " '표정 변화에 강인한 인식 성능을 확보하였다. 제안된 방법은 기존 방식 대비 약 99%의 인식 정확도를 유지하면서 평균 학습 시간을 약 '\n",
      " '68% 단축시켰다. 이 방식은 비접촉 생체 인식 기술의 보안성과 효율성을 동시에 향상시킬 수 있는 대안으로 제시된다.',\n",
      " '심화 신경망 기반 얼굴 인식 시스템은 입력 이미지에서 얼굴을 감지하고, 전처리(크기 조정, 정렬, 조명 보정 등)를 거쳐 특징을 추출한 '\n",
      " '후 신원을 확인하는 일련의 과정을 포함한다. 얼굴 특징은 주로 68개 랜드마크 좌표를 기반으로 추출되며, 이는 신경망 입력 데이터 크기를 '\n",
      " '줄이고 개인 정보 보호에 유리하다. 특징 추출에는 CNN 기반 모델이 사용되며, 완전 연결층(512→256→128→64)을 통해 최종 '\n",
      " '64차원 벡터로 표현된다. 학습은 교차 엔트로피 손실과 경사 하강법을 사용하며, 데이터 증강과 표준화를 통해 다양한 환경에서도 안정적인 '\n",
      " '인식 성능을 유지한다. 학습, 평가, 시험은 8:1:1 비율로 수행된다.',\n",
      " '제안된 좌표 기반 학습 방식은 기존 이미지 기반 신경망 모델(예: ResNet-101) 대비 학습 속도와 효율성에서 우수한 성능을 '\n",
      " '보였다. 정확도, 정밀도, 재현율 등 주요 지표 기준으로 평가되었으며, 제안 방식은 원근 변환 적용 시 다양한 얼굴 각도에서도 안정적인 '\n",
      " '인식 성능(정확도 90% 이상)을 유지하였다. 기존 방식은 높은 데이터 크기와 모델 복잡도로 인해 학습 안정화에 시간이 더 소요되며, '\n",
      " '학습 손실 0.25 도달까지 약 3배의 시간이 필요했다. 본 연구는 경량화된 얼굴 인식 기술의 가능성을 제시하며, 향후 실제 하드웨어 '\n",
      " '환경에서의 최적화 구현을 통해 실용성을 강화할 수 있음을 시사한다.',\n",
      " '요약:  \\n'\n",
      " '이 문서는 다양한 연도(2008~2023)에 발표된 기술 및 과학 관련 논문들의 메타데이터(제목 일부, 저자, DOI, 페이지, 발행 '\n",
      " '연도 등)를 포함한 목록이다. 표기 오류와 난독화된 텍스트가 많지만, 각 항목은 논문 번호, 제목 일부, DOI, 발행 연도 및 페이지 '\n",
      " '정보를 포함하고 있으며, 주로 공학, 물리학, 컴퓨터 과학 분야의 학술 자료로 추정된다. 검색 키워드로는 논문 번호, DOI, 발행 '\n",
      " '연도, 페이지 범위, 기술 키워드 등이 활용될 수 있다.',\n",
      " '요약:\\n'\n",
      " '\\n'\n",
      " '권주연: 2021년 3월부터 경상국립대학교 정보공학과 학사 과정 재학. 관심 분야는 위성통신, 마이크로회로 해석 및 설계, 계측제어.\\n'\n",
      " '\\n'\n",
      " '반태원: 경북대학교 전자공학과 학사(1998), 석사(2000), 전기전자공학과 박사(2010). 2000~2013년 네트워크 부문 '\n",
      " '근무, 2012년 9월부터 경상국립대학교 정보공학과 교수. 관심 분야는 이동통신, 자원관리, 간섭관리, 협력 및 중계통신, 인지통신, '\n",
      " '차세대 이동통신 시스템.']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(text_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85888a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
