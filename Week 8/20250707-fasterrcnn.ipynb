{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8008269,"sourceType":"datasetVersion","datasetId":3775672}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:02:08.327515Z","iopub.execute_input":"2025-07-07T01:02:08.328230Z","iopub.status.idle":"2025-07-07T01:02:08.332508Z","shell.execute_reply.started":"2025-07-07T01:02:08.328205Z","shell.execute_reply":"2025-07-07T01:02:08.331885Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"s076923/pytorch-transformer\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:03:17.943325Z","iopub.execute_input":"2025-07-07T01:03:17.943694Z","iopub.status.idle":"2025-07-07T01:04:20.246191Z","shell.execute_reply.started":"2025-07-07T01:03:17.943674Z","shell.execute_reply":"2025-07-07T01:04:20.245422Z"}},"outputs":[{"name":"stdout","text":"Mounting files to /kaggle/input/pytorch-transformer...\nPath to dataset files: /kaggle/input/pytorch-transformer\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:07:04.893260Z","iopub.execute_input":"2025-07-07T01:07:04.893935Z","iopub.status.idle":"2025-07-07T01:07:08.951097Z","shell.execute_reply.started":"2025-07-07T01:07:04.893900Z","shell.execute_reply":"2025-07-07T01:07:08.950577Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"/kaggle/input/pytorch-transformer/datasets/coco/train\n/kaggle/input/pytorch-transformer/datasets/coco/val\n/kaggle/input/pytorch-transformer/datasets/coco/annotations/train_annotations.json\n/kaggle/input/pytorch-transformer/datasets/coco/annotations/val_annotations.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"root = \"/kaggle/input/pytorch-transformer/datasets/coco/\"\nos.path.join(root, 'anno', 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:11:07.776249Z","iopub.execute_input":"2025-07-07T01:11:07.776927Z","iopub.status.idle":"2025-07-07T01:11:07.781860Z","shell.execute_reply.started":"2025-07-07T01:11:07.776901Z","shell.execute_reply":"2025-07-07T01:11:07.781142Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/pytorch-transformer/datasets/coco/anno/test'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train = True\ndirectory = \"train\" if train else \"val\"\nannotations = os.path.join(root, \"annotations\", f\"{directory}_annotations.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:13:06.073830Z","iopub.execute_input":"2025-07-07T01:13:06.074122Z","iopub.status.idle":"2025-07-07T01:13:06.078319Z","shell.execute_reply.started":"2025-07-07T01:13:06.074100Z","shell.execute_reply":"2025-07-07T01:13:06.077413Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"coco = COCO(annotations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:25:34.257537Z","iopub.execute_input":"2025-07-07T01:25:34.258260Z","iopub.status.idle":"2025-07-07T01:25:34.431351Z","shell.execute_reply.started":"2025-07-07T01:25:34.258234Z","shell.execute_reply":"2025-07-07T01:25:34.430775Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.17s)\ncreating index...\nindex created!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"coco.loadAnns(coco.getAnnIds(495357))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:35:37.715452Z","iopub.execute_input":"2025-07-07T01:35:37.715712Z","iopub.status.idle":"2025-07-07T01:35:37.720913Z","shell.execute_reply.started":"2025-07-07T01:35:37.715692Z","shell.execute_reply":"2025-07-07T01:35:37.720403Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'segmentation': [[374.46,\n    310.42,\n    386.68,\n    310.17,\n    394.32,\n    308.64,\n    398.4,\n    303.54,\n    397.38,\n    301.0,\n    401.71,\n    301.51,\n    403.49,\n    296.16,\n    402.98,\n    291.32,\n    402.22,\n    286.48,\n    400.95,\n    283.42,\n    394.32,\n    281.13,\n    391.78,\n    277.06,\n    388.98,\n    272.47,\n    387.7,\n    270.94,\n    382.1,\n    270.18,\n    378.53,\n    267.89,\n    374.46,\n    263.81,\n    368.35,\n    260.76,\n    366.05,\n    256.94,\n    363.25,\n    253.88,\n    358.67,\n    251.08,\n    357.14,\n    247.51,\n    353.83,\n    245.22,\n    351.03,\n    244.46,\n    345.93,\n    244.97,\n    342.88,\n    248.02,\n    341.35,\n    251.08,\n    339.57,\n    253.63,\n    337.02,\n    255.15,\n    338.8,\n    259.23,\n    339.41,\n    266.1,\n    346.51,\n    265.74,\n    349.35,\n    269.3,\n    342.25,\n    272.49,\n    339.41,\n    275.69,\n    343.67,\n    277.11,\n    348.29,\n    274.27,\n    353.61,\n    276.4,\n    357.17,\n    283.86,\n    357.88,\n    292.38,\n    355.75,\n    301.62,\n    352.9,\n    306.95,\n    350.42,\n    306.95,\n    347.93,\n    306.95,\n    351.48,\n    311.21,\n    356.81,\n    310.86,\n    359.3,\n    308.37,\n    362.14,\n    304.82,\n    364.98,\n    303.04,\n    366.76,\n    290.61,\n    371.38,\n    294.52,\n    374.93,\n    295.94,\n    371.38,\n    301.27,\n    373.86,\n    306.24,\n    372.44,\n    308.37,\n    373.51,\n    311.21,\n    376.35,\n    310.86]],\n  'area': 2243.7513000000004,\n  'iscrowd': 0,\n  'image_id': 495357,\n  'bbox': [337.02, 244.46, 66.47, 66.75],\n  'category_id': 2,\n  'id': 1727}]"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"class COCODataset(Dataset):\n    def __init__(self, root, train, transform=None):\n        super(self, COCODataset).__init__()\n        directory = \"train\" if train else \"val\"\n        annotations = os.path.join(root, \"annotations\", f\"{directory}_annotations.json\")\n        self.coco = COCO(annotations)\n        self.image_path = os.path.join(root, directory)\n        self.transform = transform \n        self.categories = self.__get_categories()\n        self.data = self.__load_data()\n           \n    def __get_categories(self):\n        categories = {0 : 'background'}\n        for category in self.coco.cats.values():\n            categories[category['id']] = category['name']\n        return categories\n    \n    def __load_data(self):\n        data = []\n        for _id in self.coco.imgs:\n            file_name = self.coco.loadImgs(_id)[0]['file_name']\n            image_path = os.path.join(self.image_path, file_name)\n            image = Image.open(image_path).convert(\"RGB\")\n\n            boxes = []\n            labels = []\n            anns = self.coco.loadAnns(self.coco.getAnnIds(_id))\n\n            for ann in anns:\n                x, y, w, h = ann['bbox']\n                boxes.append([x, y, x+w, y+h])\n                labels.append(ann['category_id'])\n            target = {\n                'image_id' : torch.LongTensor([_id]),\n                'boxes' : torch.FloatTensor(boxes),\n                'labels' : torch.LongTensor(labels)\n            }\n            data.append([image, target])\n        return data\n       \n    \n    def __getitem__(self, index):\n        image, target = self.data[index]\n        if self.tranform:\n            image =self.transform(image)\n        return image, target\n        \n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T01:45:32.238790Z","iopub.execute_input":"2025-07-07T01:45:32.239279Z","iopub.status.idle":"2025-07-07T01:45:32.249796Z","shell.execute_reply.started":"2025-07-07T01:45:32.239260Z","shell.execute_reply":"2025-07-07T01:45:32.248975Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from torchvision","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}